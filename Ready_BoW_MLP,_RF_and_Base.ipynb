{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR0QZJ0g04HV",
        "outputId": "deb364b9-213f-46b1-888b-cd51406332d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "  \n",
        "## for data\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "## for plotting\n",
        "## for processing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "## for bag-of-words\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Ensemble learning models\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Model evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xlrd\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import joblib \n",
        "## for bert language model\n",
        "#import transformers\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "# from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.model_selection import KFold\n",
        "from nltk.stem import PorterStemmer\n",
        "from string import punctuation\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import time\n",
        "\n",
        "%config IPCompleter.greedy=True\n",
        "%config IPCompleter.use_jedi=False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Save Classification report in a Dataframe for plotting \n",
        "\n",
        "\n",
        "def report_to_df(report, filename):\n",
        "    report = [x.split(' ') for x in report.split('\\n')]\n",
        "    header = ['Class Name']+[x for x in report[0] if x!='']\n",
        "    values = []\n",
        "    for row in report[1:-5]:\n",
        "        row = [value for value in row if value!='']\n",
        "        if row!=[]:\n",
        "            values.append(row)\n",
        "    df_rep = pd.DataFrame(data = values, columns = header)\n",
        "    joblib.dump(df_rep,prefix+filename+'report.Dataframe')\n",
        "\n",
        "\n",
        "\n",
        "# Kink to drive\n",
        "import joblib \n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "prefix = 'drive/MyDrive/Hisham_Ignacio/ICMS_ML/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean, cutoff for 250 and categroy 50 is out. \n",
        "The text is not preprocessed or tokinised. "
      ],
      "metadata": {
        "id": "obdMVIDupooo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Tf-Idf (advanced variant of BoW)\n",
        "#vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=total_dict, ngram_range=(1,2))\n",
        "\n",
        "# plot histogram\n",
        "def histo(df):\n",
        "  fig, ax = plt.subplots(figsize=(25, 15))\n",
        "  fig.suptitle(\"y\", fontsize=12)\n",
        "  df[\"Cat\"].reset_index().groupby(\"Cat\").count().sort_values(by= \"index\").plot(kind=\"barh\", legend=False, \n",
        "        ax=ax).grid(axis='x')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# remove under-represented categories\n",
        "def cat_size(df, cat_size):\n",
        "  if cat_size is not None:\n",
        "    df_minimal=df.groupby(['Cat']).filter(lambda x: len(x) >= cat_size)\n",
        "  return df_minimal\n",
        "\n",
        "\n",
        "###### -- CLEANING and Vectorisation #####\n",
        "\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = stopwords.words('english')\n",
        "stemmer = PorterStemmer()\n",
        "    \n",
        "def clean_doc(doc):\n",
        "    # split into tokens by white space\n",
        "    tokens = doc.split()\n",
        "    # prepare regex for char filtering\n",
        "    re_punc = re.compile('[%s]' % re.escape(punctuation))\n",
        "    # remove punctuation from each word\n",
        "    tokens = [re_punc.sub('', w) for w in tokens]\n",
        "    # filter out stop words\n",
        "    tokens = [w for w in tokens if not w in stopwords]\n",
        "    # filter out short tokens\n",
        "    tokens = [word for word in tokens if len(word) >= 1]\n",
        "    # Stem the token\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "def add_doc_to_vocab(docs, vocab):\n",
        "    '''\n",
        "    input:\n",
        "        docs: a list of sentences (docs)\n",
        "        vocab: a vocabulary dictionary\n",
        "    output:\n",
        "        return an updated vocabulary\n",
        "    '''\n",
        "    for doc in docs:\n",
        "        tokens = clean_doc(doc)\n",
        "        vocab.update(tokens)\n",
        "    return vocab\n",
        "        \n",
        "def doc_to_line(doc, vocab):\n",
        "    tokens = clean_doc(doc)\n",
        "    # filter by vocab\n",
        "    tokens = [token for token in tokens if token in vocab]\n",
        "    line = ' '.join(tokens)\n",
        "    return line\n",
        "\n",
        "def clean_docs(docs, vocab):\n",
        "    lines = []\n",
        "    for doc in docs:\n",
        "        line = doc_to_line(doc, vocab)\n",
        "        lines.append(line)\n",
        "    return lines\n",
        "\n",
        "def create_tokenizer(sentences):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def prepare_ready(X_train, X_test, mode):\n",
        "  print('train_x size: ', len(X_train))\n",
        "  print('train_y size: ', len(y_train))\n",
        "  print('test_x size: ', len(X_test))\n",
        "  print('test_y size: ', len(y_test))\n",
        "\n",
        "  # Instantiate a vocab object\n",
        "  vocab = Counter()\n",
        "  # Define a vocabulary for each fold\n",
        "  vocab = add_doc_to_vocab(X_train, vocab)\n",
        "  print('The number of vocab: ', len(vocab))\n",
        "\n",
        "  # Clean the sentences\n",
        "  X_train = clean_docs(X_train, vocab)\n",
        "  X_test = clean_docs(X_test, vocab)\n",
        "\n",
        "  # Define the tokenizer\n",
        "  tokenizer = create_tokenizer(X_train)\n",
        "  # encode data using the parsed mode ['freq', 'count', tfidf, etc]\n",
        "  Xtrain = tokenizer.texts_to_matrix(X_train, mode=mode)\n",
        "  Xtest = tokenizer.texts_to_matrix(X_test, mode=mode)\n",
        "  #joblib.dump((Xtrain), prefix+mode+'Train.joblib')\n",
        "  #joblib.dump((Xtest), prefix+mode+'Test.joblib')\n",
        "  print('Saved vectorised splits to disk')\n",
        "  print('Xtrain', prefix+mode+'Train.joblib')\n",
        "  print('Xtest', prefix+mode+'Test.joblib')\n",
        "  \n",
        "  return Xtrain, Xtest\n",
        "  ## Check vocabulary\n",
        "  #vocab.items()\n",
        "  # print(vocab)\n",
        "\n",
        "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
        "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "    #remove if only two charecters\n",
        "    text_big = re.sub(r'\\W*\\b\\w{1,2}\\b', '', text) \n",
        "          \n",
        "    ## Tokenize (convert from string to list)\n",
        "    lst_text = text_big.split()\n",
        "    ## remove Stopwords\n",
        "    if lst_stopwords is not None:\n",
        "        lst_text = [word for word in lst_text if word not in \n",
        "                    lst_stopwords]\n",
        "        #lst_text = ' '.join(c for c in lst_text if not c.isdigit())\n",
        "     \n",
        "\n",
        "    ## Stemming (remove -ing, -ly, ...)\n",
        "    if flg_stemm == True:\n",
        "        ps = nltk.stem.porter.PorterStemmer()\n",
        "        lst_text = [ps.stem(word) for word in lst_text]\n",
        "\n",
        "       \n",
        "\n",
        "    ## Lemmatisation (convert the word into root word)\n",
        "    if flg_lemm == True:\n",
        "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
        "                 ## removing tags\n",
        "        ## removing digits\n",
        "\n",
        "    \n",
        "           \n",
        "    ## back to string from list\n",
        "    text = \" \".join(lst_text)\n",
        "    return text\n",
        "\n",
        "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "for x in ('x', 'mm', 'cm', 'ref', 'wb', 'xx', 'per', 'm'):\n",
        "  lst_stopwords.append(x)\n",
        "\n",
        "\n",
        "# Function to clean text data\n",
        "\n",
        "def clean_text_data(df):\n",
        "\n",
        "    # Separate data\n",
        "    desc_lower = df['comment_list']\n",
        "    \n",
        "\n",
        "\n",
        "    # Remove text before \"|\" character\n",
        "    desc_split = desc_lower.str.split(\"|\")\n",
        "    desc_strip = desc_split.apply(lambda x: x[1] if len(x) > 1 else x[0])\n",
        "    # Removing digits and words containing digits\n",
        "    desc_nodigits = desc_strip.apply(lambda x: re.sub(\"\\w*\\d\\w*\", \"\", x))\n",
        "    # Removing punctuation\n",
        "    desc_nopunc = desc_nodigits.apply(lambda x: re.sub(r\"[^\\w\\s]\", \"\", x))\n",
        "    # Removing additional whitespace\n",
        "    desc_clean = desc_nopunc.apply(lambda x: re.sub(' +', ' ', x))\n",
        "    \n",
        "    \n",
        "    # Lemmatisation and stopword removal\n",
        "    # Load spacy\n",
        "    nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
        "    lemmatized = desc_clean.apply(lambda x: \" \".\\\n",
        "                                  join([token.lemma_ for token in list(nlp(x)) if (token.is_stop == False)]))\n",
        "    \n",
        "    return lemmatized"
      ],
      "metadata": {
        "id": "sHB3aSi5Rv8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIDojY0I70jw"
      },
      "outputs": [],
      "source": [
        "df= joblib.load(prefix+'df_clean.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = joblib.load(prefix+'ICMS_dataset_revised.joblib') \n",
        "Cat = {i:x for i,x in enumerate(df.ICMS.astype('category').cat.categories)}\n",
        "#y = df.Cat.astype('int')\n",
        "\n",
        "print (\"size before\")\n",
        "print (df.shape)\n",
        "\n",
        " # Remove repeated rows\n",
        "df.drop_duplicates(inplace = True)\n",
        "   \n",
        "    # For rows with identical reviews - retain only first\n",
        "df.drop_duplicates(subset = ['Description'], keep = 'first', inplace = True)\n",
        "\n",
        "    # Create mask\n",
        "missing_description = df.Description.isna()\n",
        "df = df[~missing_description]\n",
        "    \n",
        "print (\"size after\")\n",
        "print (df.shape)\n",
        "\n",
        "\n",
        "#Generate the category codes from the ICMS codes\n",
        "df['Cat'] = df.ICMS.astype('category').cat.codes\n",
        "#df.drop_duplicates()\n",
        "\n",
        "\n",
        "df[\"comment_list\"] = df[\"Description\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
        "y = df.Cat.astype('int')\n",
        "\n",
        "df[\"comment_list_new\"] = clean_text_data(df)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "2kjSDLYzsDc4",
        "outputId": "6a0e90fc-df99-416f-9ed8-dcd213253e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size before\n",
            "(123924, 2)\n",
            "size after\n",
            "(53320, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Description      ICMS  Cat  \\\n",
              "0               Filter Drains - Diameter <300mm  1.06.020   31   \n",
              "1     Filter Drains - Diameter >=300 but <450mm  1.06.020   31   \n",
              "2              Filter Drains - Diameter >=450mm  1.06.020   31   \n",
              "3             Filter Drains - Sub-base material  1.06.020   31   \n",
              "4  Filter Drains - Lightweight aggregate infill  1.06.020   31   \n",
              "\n",
              "                                comment_list  \\\n",
              "0                filter drain diameter 300mm   \n",
              "1            filter drain diameter 300 450mm   \n",
              "2                filter drain diameter 450mm   \n",
              "3              filter drain subbase material   \n",
              "4  filter drain lightweight aggregate infill   \n",
              "\n",
              "                            comment_list_new  \n",
              "0                      filter drain diameter  \n",
              "1                      filter drain diameter  \n",
              "2                      filter drain diameter  \n",
              "3              filter drain subbase material  \n",
              "4  filter drain lightweight aggregate infill  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acdc8f68-26b1-48be-bd4a-3e358cfdb016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>ICMS</th>\n",
              "      <th>Cat</th>\n",
              "      <th>comment_list</th>\n",
              "      <th>comment_list_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Filter Drains - Diameter &lt;300mm</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain diameter 300mm</td>\n",
              "      <td>filter drain diameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Filter Drains - Diameter &gt;=300 but &lt;450mm</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain diameter 300 450mm</td>\n",
              "      <td>filter drain diameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Filter Drains - Diameter &gt;=450mm</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain diameter 450mm</td>\n",
              "      <td>filter drain diameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Filter Drains - Sub-base material</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain subbase material</td>\n",
              "      <td>filter drain subbase material</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Filter Drains - Lightweight aggregate infill</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain lightweight aggregate infill</td>\n",
              "      <td>filter drain lightweight aggregate infill</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acdc8f68-26b1-48be-bd4a-3e358cfdb016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acdc8f68-26b1-48be-bd4a-3e358cfdb016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acdc8f68-26b1-48be-bd4a-3e358cfdb016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vT3CFhy76xs",
        "outputId": "98b5df6f-33d4-4c1e-9da4-9299308ac40e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/Hisham_Ignacio/ICMS_ML/df_clean.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df= joblib.load(prefix+'df_clean.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "982MYevpKq-Y",
        "outputId": "7ecc1910-7199-4a6f-9731-98a16986dce1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53320, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=cat_size(df, 250)\n",
        "histo(df)\n",
        "\n",
        "\n",
        "index_names = df[ df['Cat'] == 50 ].index\n",
        "  \n",
        "# drop these row indexes\n",
        "# from dataFrame\n",
        "df.drop(index_names, inplace = True)\n",
        "  \n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qWHDU97TuwGl",
        "outputId": "7527b4a7-9ce7-43d9-dce1-49e4613bda43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Description      ICMS  Cat  \\\n",
              "0                         Filter Drains - Diameter <300mm  1.06.020   31   \n",
              "1               Filter Drains - Diameter >=300 but <450mm  1.06.020   31   \n",
              "2                        Filter Drains - Diameter >=450mm  1.06.020   31   \n",
              "3                       Filter Drains - Sub-base material  1.06.020   31   \n",
              "4            Filter Drains - Lightweight aggregate infill  1.06.020   31   \n",
              "...                                                   ...       ...  ...   \n",
              "123912  Sheet piled retaining wall based on AZ17 secti...  1.02.050   10   \n",
              "123913  Extra over for steel sheet piling work at nigh...  1.02.050   10   \n",
              "123918             Add Hockey stick - Erection (cleansed)  1.04.050   23   \n",
              "123920                      Assistant Engineering Manager  1.08.010   35   \n",
              "123922                                   Pacakage Manager  1.08.010   35   \n",
              "\n",
              "                                             comment_list  \\\n",
              "0                             filter drain diameter 300mm   \n",
              "1                         filter drain diameter 300 450mm   \n",
              "2                             filter drain diameter 450mm   \n",
              "3                           filter drain subbase material   \n",
              "4               filter drain lightweight aggregate infill   \n",
              "...                                                   ...   \n",
              "123912  sheet piled retaining wall based az17 section ...   \n",
              "123913  extra steel sheet piling work night driving st...   \n",
              "123918                 add hockey stick erection cleansed   \n",
              "123920                      assistant engineering manager   \n",
              "123922                                   pacakage manager   \n",
              "\n",
              "                                         comment_list_new  \n",
              "0                                   filter drain diameter  \n",
              "1                                   filter drain diameter  \n",
              "2                                   filter drain diameter  \n",
              "3                           filter drain subbase material  \n",
              "4               filter drain lightweight aggregate infill  \n",
              "...                                                   ...  \n",
              "123912  sheet pile retain wall base section sheet pile...  \n",
              "123913  extra steel sheet pile work night drive steel ...  \n",
              "123918                  add hockey stick erection cleanse  \n",
              "123920                      assistant engineering manager  \n",
              "123922                                   pacakage manager  \n",
              "\n",
              "[50744 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07c1d71d-3ca2-4055-8606-d81bd11a3495\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>ICMS</th>\n",
              "      <th>Cat</th>\n",
              "      <th>comment_list</th>\n",
              "      <th>comment_list_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Filter Drains - Diameter &lt;300mm</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain diameter 300mm</td>\n",
              "      <td>filter drain diameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Filter Drains - Diameter &gt;=300 but &lt;450mm</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain diameter 300 450mm</td>\n",
              "      <td>filter drain diameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Filter Drains - Diameter &gt;=450mm</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain diameter 450mm</td>\n",
              "      <td>filter drain diameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Filter Drains - Sub-base material</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain subbase material</td>\n",
              "      <td>filter drain subbase material</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Filter Drains - Lightweight aggregate infill</td>\n",
              "      <td>1.06.020</td>\n",
              "      <td>31</td>\n",
              "      <td>filter drain lightweight aggregate infill</td>\n",
              "      <td>filter drain lightweight aggregate infill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123912</th>\n",
              "      <td>Sheet piled retaining wall based on AZ17 secti...</td>\n",
              "      <td>1.02.050</td>\n",
              "      <td>10</td>\n",
              "      <td>sheet piled retaining wall based az17 section ...</td>\n",
              "      <td>sheet pile retain wall base section sheet pile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123913</th>\n",
              "      <td>Extra over for steel sheet piling work at nigh...</td>\n",
              "      <td>1.02.050</td>\n",
              "      <td>10</td>\n",
              "      <td>extra steel sheet piling work night driving st...</td>\n",
              "      <td>extra steel sheet pile work night drive steel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123918</th>\n",
              "      <td>Add Hockey stick - Erection (cleansed)</td>\n",
              "      <td>1.04.050</td>\n",
              "      <td>23</td>\n",
              "      <td>add hockey stick erection cleansed</td>\n",
              "      <td>add hockey stick erection cleanse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123920</th>\n",
              "      <td>Assistant Engineering Manager</td>\n",
              "      <td>1.08.010</td>\n",
              "      <td>35</td>\n",
              "      <td>assistant engineering manager</td>\n",
              "      <td>assistant engineering manager</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123922</th>\n",
              "      <td>Pacakage Manager</td>\n",
              "      <td>1.08.010</td>\n",
              "      <td>35</td>\n",
              "      <td>pacakage manager</td>\n",
              "      <td>pacakage manager</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50744 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07c1d71d-3ca2-4055-8606-d81bd11a3495')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07c1d71d-3ca2-4055-8606-d81bd11a3495 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07c1d71d-3ca2-4055-8606-d81bd11a3495');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7sUfcyH1hE0"
      },
      "outputs": [],
      "source": [
        "#df.drop(columns = ['ICMS'], inplace = True)\n",
        "y = df.Cat.astype('int')\n",
        "X=df[\"comment_list_new\"]\n",
        "#X=df[\"Description\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7gdDkPN4IBd",
        "outputId": "dc6898ae-b638-4caa-9b09-782ceb75cfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40595,) (10149,) (40595,) (10149,) (50744,) (50744,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-aAGITi2a9r"
      },
      "outputs": [],
      "source": [
        "X_train=X_train.to_frame()\n",
        "X_test=X_test.to_frame()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train = list(X_train.comment_list_new)\n",
        "X_test = list(X_test.comment_list_new)"
      ],
      "metadata": {
        "id": "fcXpiRX0wr03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test=prepare_ready(X_train, X_test, 'count')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktJ2oSGZWQZX",
        "outputId": "005c1d03-34f0-439e-eee6-428485e58c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x size:  40595\n",
            "train_y size:  40595\n",
            "test_x size:  10149\n",
            "test_y size:  10149\n",
            "The number of vocab:  5908\n",
            "Saved vectorised splits to disk\n",
            "Xtrain drive/MyDrive/Hisham_Ignacio/ICMS_ML/countTrain.joblib\n",
            "Xtest drive/MyDrive/Hisham_Ignacio/ICMS_ML/countTest.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0GLOYGaWaAj",
        "outputId": "d21f6eda-82f5-4b10-b3ee-481cd90d038f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40595, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-ifKFv-3ZAc"
      },
      "outputs": [],
      "source": [
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=10, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GYiGmlpi5zwZ",
        "outputId": "50986475-da87-480b-cbc2-166891c891da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x size:  40595\n",
            "train_y size:  40595\n",
            "test_x size:  10149\n",
            "test_y size:  10149\n",
            "Epoch 1/30\n",
            "812/812 - 3s - loss: 1.3108 - accuracy: 0.6769 - val_loss: 0.5197 - val_accuracy: 0.8700 - 3s/epoch - 4ms/step\n",
            "Epoch 2/30\n",
            "812/812 - 2s - loss: 0.6136 - accuracy: 0.8466 - val_loss: 0.4095 - val_accuracy: 0.8960 - 2s/epoch - 3ms/step\n",
            "Epoch 3/30\n",
            "812/812 - 2s - loss: 0.4731 - accuracy: 0.8804 - val_loss: 0.3697 - val_accuracy: 0.9080 - 2s/epoch - 3ms/step\n",
            "Epoch 4/30\n",
            "812/812 - 2s - loss: 0.4057 - accuracy: 0.8985 - val_loss: 0.3527 - val_accuracy: 0.9134 - 2s/epoch - 3ms/step\n",
            "Epoch 5/30\n",
            "812/812 - 2s - loss: 0.3481 - accuracy: 0.9102 - val_loss: 0.3483 - val_accuracy: 0.9157 - 2s/epoch - 3ms/step\n",
            "Epoch 6/30\n",
            "812/812 - 2s - loss: 0.3095 - accuracy: 0.9191 - val_loss: 0.3478 - val_accuracy: 0.9188 - 2s/epoch - 3ms/step\n",
            "Epoch 7/30\n",
            "812/812 - 2s - loss: 0.2836 - accuracy: 0.9267 - val_loss: 0.3524 - val_accuracy: 0.9186 - 2s/epoch - 3ms/step\n",
            "Epoch 8/30\n",
            "812/812 - 2s - loss: 0.2632 - accuracy: 0.9318 - val_loss: 0.3532 - val_accuracy: 0.9209 - 2s/epoch - 3ms/step\n",
            "Epoch 9/30\n",
            "812/812 - 2s - loss: 0.2401 - accuracy: 0.9357 - val_loss: 0.3525 - val_accuracy: 0.9232 - 2s/epoch - 3ms/step\n",
            "Epoch 10/30\n",
            "812/812 - 2s - loss: 0.2289 - accuracy: 0.9384 - val_loss: 0.3553 - val_accuracy: 0.9246 - 2s/epoch - 3ms/step\n",
            "Epoch 11/30\n",
            "812/812 - 2s - loss: 0.2167 - accuracy: 0.9420 - val_loss: 0.3657 - val_accuracy: 0.9244 - 2s/epoch - 3ms/step\n",
            "Epoch 12/30\n",
            "812/812 - 2s - loss: 0.2041 - accuracy: 0.9450 - val_loss: 0.3700 - val_accuracy: 0.9249 - 2s/epoch - 3ms/step\n",
            "Epoch 13/30\n",
            "812/812 - 2s - loss: 0.1935 - accuracy: 0.9464 - val_loss: 0.3805 - val_accuracy: 0.9257 - 2s/epoch - 3ms/step\n",
            "Epoch 14/30\n",
            "812/812 - 2s - loss: 0.1846 - accuracy: 0.9482 - val_loss: 0.3889 - val_accuracy: 0.9266 - 2s/epoch - 3ms/step\n",
            "Epoch 15/30\n",
            "812/812 - 2s - loss: 0.1791 - accuracy: 0.9515 - val_loss: 0.3936 - val_accuracy: 0.9278 - 2s/epoch - 3ms/step\n",
            "Epoch 16/30\n",
            "812/812 - 2s - loss: 0.1703 - accuracy: 0.9534 - val_loss: 0.4053 - val_accuracy: 0.9258 - 2s/epoch - 3ms/step\n",
            "Epoch 17/30\n",
            "812/812 - 2s - loss: 0.1670 - accuracy: 0.9534 - val_loss: 0.4084 - val_accuracy: 0.9256 - 2s/epoch - 3ms/step\n",
            "Epoch 18/30\n",
            "812/812 - 2s - loss: 0.1584 - accuracy: 0.9548 - val_loss: 0.4233 - val_accuracy: 0.9262 - 2s/epoch - 3ms/step\n",
            "Epoch 19/30\n",
            "812/812 - 2s - loss: 0.1527 - accuracy: 0.9578 - val_loss: 0.4319 - val_accuracy: 0.9262 - 2s/epoch - 3ms/step\n",
            "Epoch 20/30\n",
            "812/812 - 2s - loss: 0.1484 - accuracy: 0.9583 - val_loss: 0.4358 - val_accuracy: 0.9252 - 2s/epoch - 3ms/step\n",
            "Epoch 21/30\n",
            "812/812 - 2s - loss: 0.1422 - accuracy: 0.9603 - val_loss: 0.4500 - val_accuracy: 0.9249 - 2s/epoch - 3ms/step\n",
            "Epoch 22/30\n",
            "812/812 - 2s - loss: 0.1422 - accuracy: 0.9595 - val_loss: 0.4429 - val_accuracy: 0.9266 - 2s/epoch - 3ms/step\n",
            "Epoch 23/30\n",
            "812/812 - 2s - loss: 0.1359 - accuracy: 0.9621 - val_loss: 0.4654 - val_accuracy: 0.9266 - 2s/epoch - 3ms/step\n",
            "Epoch 24/30\n",
            "812/812 - 2s - loss: 0.1322 - accuracy: 0.9605 - val_loss: 0.4630 - val_accuracy: 0.9277 - 2s/epoch - 3ms/step\n",
            "Epoch 25/30\n",
            "812/812 - 2s - loss: 0.1317 - accuracy: 0.9628 - val_loss: 0.4677 - val_accuracy: 0.9295 - 2s/epoch - 3ms/step\n",
            "Epoch 26/30\n",
            "812/812 - 2s - loss: 0.1274 - accuracy: 0.9638 - val_loss: 0.4815 - val_accuracy: 0.9284 - 2s/epoch - 3ms/step\n",
            "Epoch 27/30\n",
            "812/812 - 2s - loss: 0.1267 - accuracy: 0.9639 - val_loss: 0.4903 - val_accuracy: 0.9273 - 2s/epoch - 3ms/step\n",
            "Epoch 28/30\n",
            "812/812 - 2s - loss: 0.1234 - accuracy: 0.9655 - val_loss: 0.4959 - val_accuracy: 0.9268 - 2s/epoch - 3ms/step\n",
            "Epoch 29/30\n",
            "812/812 - 2s - loss: 0.1230 - accuracy: 0.9651 - val_loss: 0.5090 - val_accuracy: 0.9289 - 2s/epoch - 3ms/step\n",
            "Epoch 30/30\n",
            "812/812 - 2s - loss: 0.1194 - accuracy: 0.9648 - val_loss: 0.5244 - val_accuracy: 0.9271 - 2s/epoch - 3ms/step\n",
            "Test Accuracy: 92.70864129066467\n",
            "51/51 [==============================] - 0s 3ms/step\n",
            "[29 40 34 ... 22 25 36]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84       186\n",
            "           1       0.93      0.80      0.86        54\n",
            "           3       0.94      0.89      0.92       141\n",
            "           4       0.90      0.94      0.92       532\n",
            "           8       0.90      0.86      0.88       254\n",
            "           9       0.89      0.94      0.92       432\n",
            "          10       0.95      0.95      0.95       442\n",
            "          11       0.95      0.98      0.97        99\n",
            "          12       0.99      0.89      0.94        94\n",
            "          13       0.90      0.95      0.93       390\n",
            "          15       0.96      0.93      0.95       256\n",
            "          17       0.92      0.94      0.93        63\n",
            "          18       0.91      0.89      0.90       249\n",
            "          19       0.89      0.85      0.87       131\n",
            "          22       0.98      0.98      0.98      1336\n",
            "          23       0.93      0.93      0.93       287\n",
            "          24       0.92      0.91      0.91       358\n",
            "          25       0.91      0.91      0.91       150\n",
            "          26       0.94      1.00      0.97        66\n",
            "          27       0.90      1.00      0.95        62\n",
            "          28       0.92      0.98      0.95       283\n",
            "          29       0.90      0.89      0.89       418\n",
            "          30       0.89      0.84      0.86        92\n",
            "          31       0.95      0.97      0.96      1041\n",
            "          32       0.97      0.96      0.97       594\n",
            "          33       0.96      0.92      0.94       141\n",
            "          34       0.97      0.98      0.98       291\n",
            "          35       0.95      0.94      0.95       459\n",
            "          36       0.86      0.84      0.85       404\n",
            "          38       0.86      0.87      0.86        90\n",
            "          40       0.85      0.81      0.83       687\n",
            "          43       0.81      0.75      0.78        67\n",
            "\n",
            "    accuracy                           0.93     10149\n",
            "   macro avg       0.92      0.91      0.91     10149\n",
            "weighted avg       0.93      0.93      0.93     10149\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#########################\n",
        "# The Dense Sequential Model MLP #\n",
        "#########################\n",
        "\n",
        "\n",
        "\n",
        "def create_tokenizer(sentences):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    return tokenizer\n",
        "\n",
        "def train_mlp_3(train_x, train_y, test_x, test_y, batch_size = 50, epochs = 30, verbose =2):\n",
        "    \n",
        "    n_words = train_x.shape[1]\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(units=300, activation='relu', input_shape=(n_words,)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense( units=50, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense( units=44, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    history= model.fit(train_x, train_y, batch_size, epochs, verbose, callbacks = [callbacks], validation_data=(test_x, test_y))\n",
        "\n",
        "    plt.plot(history.history['accuracy'], label='train'); plt.plot(history.history['val_accuracy'], label='test'); plt.title('opt=', pad=-80)\n",
        "    return model\n",
        "\n",
        "# Separate the sentences and the labels for training and testing\n",
        "train_x = list(X_train.comment_list_new)\n",
        "train_y = y_train\n",
        "print('train_x size: ', len(train_x))\n",
        "print('train_y size: ', len(train_y))\n",
        "\n",
        "test_x = list(X_test.comment_list_new)\n",
        "test_y = y_test\n",
        "print('test_x size: ', len(test_x))\n",
        "print('test_y size: ', len(test_y))\n",
        "\n",
        "\n",
        "mode='count'\n",
        "    \n",
        "# Define the tokenizer\n",
        "tokenizer = create_tokenizer(train_x)\n",
        "    \n",
        "# encode data using freq mode\n",
        "Xtrain = tokenizer.texts_to_matrix(train_x, mode=mode)\n",
        "Xtest = tokenizer.texts_to_matrix(test_x, mode=mode)\n",
        "\n",
        "# train the model\n",
        "model = train_mlp_3(Xtrain, train_y, Xtest, test_y, epochs = 30)\n",
        "\n",
        "# evaluate the model\n",
        "loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
        "print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "# get the ground truth of your data. \n",
        "test_labels=test_y \n",
        "\n",
        "# predict the probability distribution of the data\n",
        "predictions=model.predict(Xtest, steps=51, verbose=1)\n",
        "\n",
        "# get the class with highest probability for each sample\n",
        "y_pred = np.argmax(predictions, axis=-1)\n",
        "print(y_pred)\n",
        "# get the classification report\n",
        "\n",
        "\n",
        "C_report=classification_report(test_labels, y_pred)\n",
        "print(C_report)\n",
        "\n",
        "#Pandas format of the report\n",
        "report_to_df(C_report, \"BoW-MLP-300\"+mode)\n",
        "#Save C_report \n",
        "\n",
        "\n",
        "## Change name for reference\n",
        "text_file = open(prefix+\"BoW-MLP-300\"+mode, \"w\")\n",
        "n = text_file.write(C_report)\n",
        "text_file.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wBEXiWQrmT8",
        "outputId": "625968ce-1280-4435-ee10-50a47cab9c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10149, 16919)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(warm_start=True, max_features=30,\n",
        "            random_state=127,\n",
        "            n_estimators=600,\n",
        "            n_jobs=-1)\n",
        "clf.fit(Xtrain, train_y)\n",
        "\n",
        "acc = clf.score(Xtest, y_test)\n",
        "print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "y_pred = clf.predict(Xtest)\n",
        "#text_file = open(prefix+\"CR_RM_200\", \"w\")\n",
        "#n = text_file.write(C_report)\n",
        "#text_file.close()\n",
        "\n",
        "    # predict the probability distribution of the data\n",
        "test_labels=test_y\n",
        "#predictions=model.predict(test_x, steps=51, verbose=1)\n",
        "\n",
        "# get the class with highest probability for each sample\n",
        "\n",
        "print(y_pred)\n",
        "    # get the classification report\n",
        "\n",
        "\n",
        "C_report=classification_report(test_labels, y_pred)\n",
        "print(C_report)\n",
        "\n",
        "\n",
        "    #Pandas format of the report\n",
        "#report_to_df(C_report, \"RF600-count\")\n",
        "#Save C_report \n",
        "\n",
        "\n",
        "        ## Change name for reference\n",
        "#text_file = open(perfix3+ 'RF600-count.txt', \"w\")\n",
        "#n = text_file.write(C_report)\n",
        "#text_file.close()    \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bAioAFG9YyA",
        "outputId": "5a7e46de-cc13-4a55-c882-240eaf0556ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 92.62981574539364\n",
            "[ 4 35 22 ... 22  4 40]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87       186\n",
            "           1       1.00      0.74      0.85        54\n",
            "           3       0.97      0.87      0.91       141\n",
            "           4       0.94      0.94      0.94       532\n",
            "           8       0.88      0.85      0.86       254\n",
            "           9       0.95      0.95      0.95       432\n",
            "          10       0.96      0.96      0.96       442\n",
            "          11       0.95      0.96      0.95        99\n",
            "          12       0.96      0.90      0.93        94\n",
            "          13       0.92      0.94      0.93       390\n",
            "          15       0.93      0.90      0.91       256\n",
            "          17       0.95      0.90      0.93        63\n",
            "          18       0.91      0.91      0.91       249\n",
            "          19       0.92      0.82      0.87       131\n",
            "          22       0.99      0.99      0.99      1336\n",
            "          23       0.95      0.92      0.93       287\n",
            "          24       0.94      0.92      0.93       358\n",
            "          25       0.97      0.97      0.97       150\n",
            "          26       0.98      0.88      0.93        66\n",
            "          27       0.98      1.00      0.99        62\n",
            "          28       0.97      0.98      0.97       283\n",
            "          29       0.92      0.90      0.91       418\n",
            "          30       0.91      0.85      0.88        92\n",
            "          31       0.96      0.95      0.96      1041\n",
            "          32       0.96      0.97      0.96       594\n",
            "          33       0.98      0.93      0.96       141\n",
            "          34       0.98      0.97      0.97       291\n",
            "          35       0.90      0.94      0.92       459\n",
            "          36       0.89      0.83      0.86       404\n",
            "          38       0.86      0.71      0.78        90\n",
            "          40       0.71      0.86      0.78       687\n",
            "          43       0.89      0.72      0.79        67\n",
            "\n",
            "    accuracy                           0.93     10149\n",
            "   macro avg       0.93      0.90      0.91     10149\n",
            "weighted avg       0.93      0.93      0.93     10149\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARbYaxj4Gq03"
      },
      "outputs": [],
      "source": [
        "report_to_df(C_report, \"BoW-MLP-300\"+mode)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQANLyDa-31S"
      },
      "source": [
        "# Word2Vec with TCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUk5KCrf-zaB"
      },
      "outputs": [],
      "source": [
        "word2vec=joblib.load(prefix+'word2vec-google-news-300.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMuLy-EbIjK3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, Dropout, MaxPool1D, Flatten, Dense, Bidirectional, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define a function to compute the max length of sequence\n",
        "def max_length(sequences):\n",
        "    '''\n",
        "    input:\n",
        "        sequences: a 2D list of integer sequences\n",
        "    output:\n",
        "        max_length: the max length of the sequences\n",
        "    '''\n",
        "    max_length = 0\n",
        "    for i, seq in enumerate(sequences):\n",
        "        length = len(seq)\n",
        "        if max_length < length:\n",
        "            max_length = length\n",
        "    return max_length\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV34gLH7EKjs"
      },
      "source": [
        "Checking how many words word2vec finds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc7VpKLPDttp"
      },
      "outputs": [],
      "source": [
        "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
        "    '''\n",
        "    input:\n",
        "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
        "        word_to_index: word to index mapping from training set\n",
        "    '''\n",
        "    \n",
        "    vocab_size = len(word_to_index) + 1\n",
        "    count = 0\n",
        "    # Set each row \"idx\" of the embedding matrix to be \n",
        "    # the word vector representation of the idx'th word of the vocabulary\n",
        "    for word, idx in word_to_index.items():\n",
        "        if word in word_to_vec_map:\n",
        "            count+=1\n",
        "            \n",
        "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNy5AELiEEos",
        "outputId": "a7632800-8bfe-412e-806f-dfd8bceb1315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4535 words present from 7321 training vocabulary in the set of pre-trained word vector\n"
          ]
        }
      ],
      "source": [
        "oov_tok = \"<UNK>\"\n",
        "# Separate the sentences and the labels\n",
        "sentences, labels = list(X), list(y)\n",
        "\n",
        "# Cleaning and Tokenization\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "training_words_in_word2vector(word2vec, word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT-q9xNJGOHx"
      },
      "outputs": [],
      "source": [
        "emb_mean = word2vec.vectors.mean()\n",
        "emb_std = word2vec.vectors.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gFowS-fGThk"
      },
      "source": [
        "## Defning embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3t2CjYVGAkO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "def pretrained_embedding_matrix(word_to_vec_map, word_to_index, emb_mean, emb_std):\n",
        "    '''\n",
        "    input:\n",
        "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
        "        word_to_index: word to index mapping from training set\n",
        "    '''\n",
        "    np.random.seed(2021)\n",
        "    \n",
        "    # adding 1 to fit Keras embedding (requirement)\n",
        "    vocab_size = len(word_to_index) + 1\n",
        "    # define dimensionality of your pre-trained word vectors (= 300)\n",
        "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
        "    \n",
        "    # initialize the matrix with generic normal distribution values\n",
        "    embed_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, emb_dim))\n",
        "    \n",
        "    # Set each row \"idx\" of the embedding matrix to be \n",
        "    # the word vector representation of the idx'th word of the vocabulary\n",
        "    for word, idx in word_to_index.items():\n",
        "        if word in word_to_vec_map:\n",
        "            embed_matrix[idx] = word_to_vec_map.get_vector(word)\n",
        "            \n",
        "    return embed_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkz245-GEFc",
        "outputId": "b355e36b-e372-4af1-d48d-1e79eb2cc45a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.19468211,  0.08648376, -0.05924511, ..., -0.16683994,\n",
              "        -0.09975549, -0.08595189],\n",
              "       [-0.13509196, -0.07441947,  0.15388953, ..., -0.05400787,\n",
              "        -0.13156594, -0.05996158],\n",
              "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
              "        -0.03930664,  0.20996094],\n",
              "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
              "        -0.01019287,  0.02075195],\n",
              "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
              "        -0.23144531,  0.04614258]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
        "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i, emb_mean, emb_std)\n",
        "em_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5VDq9huFQZx"
      },
      "outputs": [],
      "source": [
        "pip install keras-tcn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S64y9p3cGZGH"
      },
      "source": [
        "## the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO2DeN21EmIJ"
      },
      "outputs": [],
      "source": [
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import concatenate, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def define_model_2(kernel_size = 3, activation='relu', input_dim = None, \n",
        "                   output_dim=300, max_length = None, emb_matrix = None):\n",
        "    \n",
        "    inp = Input( shape=(max_length,))\n",
        "    x = Embedding(input_dim=input_dim, \n",
        "                  output_dim=output_dim, \n",
        "                  input_length=max_length,\n",
        "                  # Assign the embedding weight with word2vec embedding marix\n",
        "                  weights = [emb_matrix],\n",
        "                  # Set the weight to be not trainable (static)\n",
        "                  trainable = False)(inp)\n",
        "    \n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    \n",
        "    x = TCN(128,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn1')(x)\n",
        "    x = TCN(64,dilations = [1, 2, 4], return_sequences=True, activation = activation, name = 'tcn2')(x)\n",
        "    \n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(16, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(51, activation=\"softmax\")(conc)    \n",
        "\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile( loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_mvGh5qGilj"
      },
      "outputs": [],
      "source": [
        "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNzm8e-kGuWD"
      },
      "outputs": [],
      "source": [
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=20, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq0MML4tG1IV",
        "outputId": "f774355b-9771-434c-d2f5-377117a89432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------\n",
            "Training 1: relu activation, 3 kernel size.\n",
            "-------------------------------------------\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 28s 16ms/step - loss: 3.1354 - accuracy: 0.1602 - val_loss: 2.9664 - val_accuracy: 0.1895\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9715 - accuracy: 0.1883 - val_loss: 2.9120 - val_accuracy: 0.1954\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9427 - accuracy: 0.1920 - val_loss: 2.9105 - val_accuracy: 0.1925\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9336 - accuracy: 0.1932 - val_loss: 2.8993 - val_accuracy: 0.1940\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9250 - accuracy: 0.1945 - val_loss: 2.9000 - val_accuracy: 0.1971\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9186 - accuracy: 0.1968 - val_loss: 2.8939 - val_accuracy: 0.1966\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9191 - accuracy: 0.1945 - val_loss: 2.8959 - val_accuracy: 0.1949\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9135 - accuracy: 0.1952 - val_loss: 2.9017 - val_accuracy: 0.1954\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9123 - accuracy: 0.1941 - val_loss: 2.8946 - val_accuracy: 0.1984\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9075 - accuracy: 0.1949 - val_loss: 2.8885 - val_accuracy: 0.1997\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9086 - accuracy: 0.1965 - val_loss: 2.8880 - val_accuracy: 0.1961\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9061 - accuracy: 0.1968 - val_loss: 2.8871 - val_accuracy: 0.1955\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9080 - accuracy: 0.1953 - val_loss: 2.8887 - val_accuracy: 0.1976\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9048 - accuracy: 0.1979 - val_loss: 2.8871 - val_accuracy: 0.1963\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.9037 - accuracy: 0.1955 - val_loss: 2.8852 - val_accuracy: 0.1989\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9024 - accuracy: 0.1971 - val_loss: 2.8870 - val_accuracy: 0.1960\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8993 - accuracy: 0.1975 - val_loss: 2.8839 - val_accuracy: 0.1995\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8981 - accuracy: 0.1980 - val_loss: 2.8836 - val_accuracy: 0.2003\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8970 - accuracy: 0.1982 - val_loss: 2.8901 - val_accuracy: 0.1977\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8965 - accuracy: 0.1971 - val_loss: 2.8825 - val_accuracy: 0.1983\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8945 - accuracy: 0.1963 - val_loss: 2.8820 - val_accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8949 - accuracy: 0.1971 - val_loss: 2.8828 - val_accuracy: 0.1973\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8926 - accuracy: 0.2010 - val_loss: 2.8831 - val_accuracy: 0.2010\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8910 - accuracy: 0.1985 - val_loss: 2.8810 - val_accuracy: 0.2013\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8911 - accuracy: 0.1991 - val_loss: 2.8802 - val_accuracy: 0.2002\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8895 - accuracy: 0.2009 - val_loss: 2.8851 - val_accuracy: 0.1988\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 11s 14ms/step - loss: 2.8870 - accuracy: 0.2004 - val_loss: 2.8859 - val_accuracy: 0.1948\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8879 - accuracy: 0.1977 - val_loss: 2.8826 - val_accuracy: 0.2008\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8881 - accuracy: 0.2000 - val_loss: 2.8823 - val_accuracy: 0.2006\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8865 - accuracy: 0.1989 - val_loss: 2.8841 - val_accuracy: 0.1981\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8867 - accuracy: 0.1999 - val_loss: 2.8813 - val_accuracy: 0.2027\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8835 - accuracy: 0.2008 - val_loss: 2.8851 - val_accuracy: 0.1982\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8857 - accuracy: 0.2014 - val_loss: 2.8841 - val_accuracy: 0.2002\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8851 - accuracy: 0.2004 - val_loss: 2.8878 - val_accuracy: 0.1995\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8818 - accuracy: 0.2021 - val_loss: 2.8843 - val_accuracy: 0.2021\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8823 - accuracy: 0.1998 - val_loss: 2.8819 - val_accuracy: 0.2013\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8836 - accuracy: 0.1989 - val_loss: 2.8837 - val_accuracy: 0.2039\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8815 - accuracy: 0.2006 - val_loss: 2.8854 - val_accuracy: 0.2014\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8829 - accuracy: 0.1993 - val_loss: 2.8811 - val_accuracy: 0.1995\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8803 - accuracy: 0.2024 - val_loss: 2.8825 - val_accuracy: 0.2026\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8829 - accuracy: 0.2007 - val_loss: 2.8822 - val_accuracy: 0.1985\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8817 - accuracy: 0.2013 - val_loss: 2.8811 - val_accuracy: 0.1975\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8794 - accuracy: 0.2024 - val_loss: 2.8827 - val_accuracy: 0.2036\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8808 - accuracy: 0.2012 - val_loss: 2.8844 - val_accuracy: 0.2013\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8786 - accuracy: 0.2014 - val_loss: 2.8847 - val_accuracy: 0.2006\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8781 - accuracy: 0.2004 - val_loss: 2.8857 - val_accuracy: 0.1993\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8782 - accuracy: 0.2006 - val_loss: 2.8825 - val_accuracy: 0.2016\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8802 - accuracy: 0.2020 - val_loss: 2.8942 - val_accuracy: 0.1977\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8757 - accuracy: 0.2006 - val_loss: 2.8906 - val_accuracy: 0.1991\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8774 - accuracy: 0.2021 - val_loss: 2.8858 - val_accuracy: 0.2014\n",
            "Test Accuracy: 20.142550766468048\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 14s 15ms/step - loss: 3.1760 - accuracy: 0.1552 - val_loss: 2.9666 - val_accuracy: 0.1913\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9886 - accuracy: 0.1830 - val_loss: 2.9270 - val_accuracy: 0.1932\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9598 - accuracy: 0.1875 - val_loss: 2.9176 - val_accuracy: 0.1957\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9479 - accuracy: 0.1899 - val_loss: 2.9060 - val_accuracy: 0.1970\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9423 - accuracy: 0.1913 - val_loss: 2.9083 - val_accuracy: 0.1947\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9385 - accuracy: 0.1923 - val_loss: 2.9122 - val_accuracy: 0.1928\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9353 - accuracy: 0.1913 - val_loss: 2.9066 - val_accuracy: 0.1960\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9347 - accuracy: 0.1918 - val_loss: 2.9077 - val_accuracy: 0.1953\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9326 - accuracy: 0.1916 - val_loss: 2.9099 - val_accuracy: 0.1972\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9310 - accuracy: 0.1915 - val_loss: 2.9018 - val_accuracy: 0.1970\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9305 - accuracy: 0.1917 - val_loss: 2.9038 - val_accuracy: 0.1961\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9269 - accuracy: 0.1912 - val_loss: 2.9034 - val_accuracy: 0.1965\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9268 - accuracy: 0.1925 - val_loss: 2.9096 - val_accuracy: 0.1940\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9241 - accuracy: 0.1932 - val_loss: 2.8994 - val_accuracy: 0.1993\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9205 - accuracy: 0.1949 - val_loss: 2.8974 - val_accuracy: 0.1963\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9214 - accuracy: 0.1925 - val_loss: 2.9029 - val_accuracy: 0.1980\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9196 - accuracy: 0.1937 - val_loss: 2.8961 - val_accuracy: 0.1976\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9168 - accuracy: 0.1941 - val_loss: 2.8942 - val_accuracy: 0.1973\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9159 - accuracy: 0.1958 - val_loss: 2.8968 - val_accuracy: 0.2005\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9154 - accuracy: 0.1942 - val_loss: 2.8947 - val_accuracy: 0.1993\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9133 - accuracy: 0.1939 - val_loss: 2.8934 - val_accuracy: 0.2004\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9114 - accuracy: 0.1951 - val_loss: 2.8916 - val_accuracy: 0.1994\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9132 - accuracy: 0.1946 - val_loss: 2.8939 - val_accuracy: 0.1999\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9112 - accuracy: 0.1941 - val_loss: 2.8930 - val_accuracy: 0.1983\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9111 - accuracy: 0.1960 - val_loss: 2.8924 - val_accuracy: 0.2010\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9107 - accuracy: 0.1936 - val_loss: 2.8945 - val_accuracy: 0.1989\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9086 - accuracy: 0.1968 - val_loss: 2.8943 - val_accuracy: 0.2015\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9068 - accuracy: 0.1957 - val_loss: 2.8957 - val_accuracy: 0.2004\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9079 - accuracy: 0.1963 - val_loss: 2.8992 - val_accuracy: 0.2006\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9078 - accuracy: 0.1962 - val_loss: 2.8934 - val_accuracy: 0.2021\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9086 - accuracy: 0.1953 - val_loss: 2.8920 - val_accuracy: 0.2023\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9086 - accuracy: 0.1937 - val_loss: 2.8910 - val_accuracy: 0.2014\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9065 - accuracy: 0.1953 - val_loss: 2.8936 - val_accuracy: 0.2030\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9062 - accuracy: 0.1964 - val_loss: 2.8929 - val_accuracy: 0.1993\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9047 - accuracy: 0.1954 - val_loss: 2.8943 - val_accuracy: 0.2003\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9038 - accuracy: 0.1955 - val_loss: 2.8922 - val_accuracy: 0.2017\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9053 - accuracy: 0.1961 - val_loss: 2.8964 - val_accuracy: 0.1987\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9070 - accuracy: 0.1942 - val_loss: 2.8940 - val_accuracy: 0.2010\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9045 - accuracy: 0.1987 - val_loss: 2.8962 - val_accuracy: 0.2026\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9043 - accuracy: 0.1976 - val_loss: 2.8983 - val_accuracy: 0.1988\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9029 - accuracy: 0.1948 - val_loss: 2.8919 - val_accuracy: 0.1997\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9035 - accuracy: 0.1956 - val_loss: 2.8960 - val_accuracy: 0.1994\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9026 - accuracy: 0.1964 - val_loss: 2.8997 - val_accuracy: 0.2020\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8999 - accuracy: 0.1962 - val_loss: 2.8960 - val_accuracy: 0.2002\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9013 - accuracy: 0.1994 - val_loss: 2.8970 - val_accuracy: 0.2020\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8976 - accuracy: 0.1980 - val_loss: 2.8951 - val_accuracy: 0.2010\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8963 - accuracy: 0.1967 - val_loss: 2.8960 - val_accuracy: 0.2026\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8946 - accuracy: 0.1980 - val_loss: 2.8963 - val_accuracy: 0.2030\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8928 - accuracy: 0.1981 - val_loss: 2.8912 - val_accuracy: 0.2006\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8923 - accuracy: 0.1984 - val_loss: 2.9037 - val_accuracy: 0.2024\n",
            "Test Accuracy: 20.240187644958496\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 14s 15ms/step - loss: 3.1787 - accuracy: 0.1463 - val_loss: 2.9740 - val_accuracy: 0.1834\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9876 - accuracy: 0.1829 - val_loss: 2.9276 - val_accuracy: 0.1975\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9589 - accuracy: 0.1869 - val_loss: 2.9232 - val_accuracy: 0.1941\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9465 - accuracy: 0.1878 - val_loss: 2.9173 - val_accuracy: 0.1971\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9390 - accuracy: 0.1887 - val_loss: 2.9035 - val_accuracy: 0.1972\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9305 - accuracy: 0.1895 - val_loss: 2.8987 - val_accuracy: 0.1981\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9275 - accuracy: 0.1903 - val_loss: 2.8981 - val_accuracy: 0.1976\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9253 - accuracy: 0.1940 - val_loss: 2.9018 - val_accuracy: 0.1975\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9235 - accuracy: 0.1932 - val_loss: 2.9005 - val_accuracy: 0.1967\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9189 - accuracy: 0.1941 - val_loss: 2.8999 - val_accuracy: 0.1995\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9190 - accuracy: 0.1926 - val_loss: 2.8977 - val_accuracy: 0.1985\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9174 - accuracy: 0.1952 - val_loss: 2.8964 - val_accuracy: 0.1998\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9166 - accuracy: 0.1937 - val_loss: 2.8890 - val_accuracy: 0.2006\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9123 - accuracy: 0.1945 - val_loss: 2.8923 - val_accuracy: 0.1980\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9090 - accuracy: 0.1946 - val_loss: 2.8877 - val_accuracy: 0.1984\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9091 - accuracy: 0.1945 - val_loss: 2.8916 - val_accuracy: 0.2010\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9098 - accuracy: 0.1963 - val_loss: 2.8881 - val_accuracy: 0.1958\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9084 - accuracy: 0.1928 - val_loss: 2.8861 - val_accuracy: 0.2009\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9060 - accuracy: 0.1952 - val_loss: 2.8934 - val_accuracy: 0.1979\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9022 - accuracy: 0.1955 - val_loss: 2.8868 - val_accuracy: 0.2008\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9030 - accuracy: 0.1973 - val_loss: 2.8861 - val_accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9023 - accuracy: 0.1949 - val_loss: 2.8884 - val_accuracy: 0.1986\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9006 - accuracy: 0.1967 - val_loss: 2.8896 - val_accuracy: 0.1999\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9028 - accuracy: 0.1960 - val_loss: 2.8870 - val_accuracy: 0.2005\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8991 - accuracy: 0.1975 - val_loss: 2.8878 - val_accuracy: 0.1972\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9012 - accuracy: 0.1969 - val_loss: 2.8857 - val_accuracy: 0.2033\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8983 - accuracy: 0.1970 - val_loss: 2.8876 - val_accuracy: 0.1951\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8971 - accuracy: 0.1973 - val_loss: 2.8858 - val_accuracy: 0.1991\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8979 - accuracy: 0.1971 - val_loss: 2.8839 - val_accuracy: 0.1997\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8970 - accuracy: 0.1985 - val_loss: 2.8884 - val_accuracy: 0.2005\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8933 - accuracy: 0.1990 - val_loss: 2.8845 - val_accuracy: 0.1997\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8934 - accuracy: 0.1968 - val_loss: 2.8813 - val_accuracy: 0.2006\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8940 - accuracy: 0.1979 - val_loss: 2.8853 - val_accuracy: 0.2041\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8935 - accuracy: 0.1967 - val_loss: 2.8852 - val_accuracy: 0.2035\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8961 - accuracy: 0.1979 - val_loss: 2.8842 - val_accuracy: 0.2000\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8926 - accuracy: 0.1987 - val_loss: 2.8896 - val_accuracy: 0.1990\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8914 - accuracy: 0.1995 - val_loss: 2.8836 - val_accuracy: 0.2016\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8908 - accuracy: 0.1997 - val_loss: 2.8808 - val_accuracy: 0.2033\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8908 - accuracy: 0.1988 - val_loss: 2.8856 - val_accuracy: 0.2024\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8891 - accuracy: 0.1994 - val_loss: 2.8917 - val_accuracy: 0.2024\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8882 - accuracy: 0.1987 - val_loss: 2.8874 - val_accuracy: 0.2031\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8907 - accuracy: 0.1996 - val_loss: 2.8908 - val_accuracy: 0.2036\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8908 - accuracy: 0.2001 - val_loss: 2.8822 - val_accuracy: 0.2028\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8869 - accuracy: 0.2007 - val_loss: 2.8858 - val_accuracy: 0.2018\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8880 - accuracy: 0.2002 - val_loss: 2.8899 - val_accuracy: 0.2015\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8891 - accuracy: 0.1996 - val_loss: 2.8912 - val_accuracy: 0.1997\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8881 - accuracy: 0.2003 - val_loss: 2.8871 - val_accuracy: 0.2034\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8888 - accuracy: 0.2006 - val_loss: 2.8891 - val_accuracy: 0.2030\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.8881 - accuracy: 0.1998 - val_loss: 2.8848 - val_accuracy: 0.2033\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8881 - accuracy: 0.2000 - val_loss: 2.8897 - val_accuracy: 0.2034\n",
            "Test Accuracy: 20.337824523448944\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 15ms/step - loss: 3.1879 - accuracy: 0.1570 - val_loss: 2.9828 - val_accuracy: 0.1922\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 3.0055 - accuracy: 0.1829 - val_loss: 2.9303 - val_accuracy: 0.1951\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9733 - accuracy: 0.1862 - val_loss: 2.9334 - val_accuracy: 0.1936\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9640 - accuracy: 0.1861 - val_loss: 2.9223 - val_accuracy: 0.1962\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9576 - accuracy: 0.1854 - val_loss: 2.9238 - val_accuracy: 0.1961\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9547 - accuracy: 0.1873 - val_loss: 2.9152 - val_accuracy: 0.1941\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9500 - accuracy: 0.1864 - val_loss: 2.9140 - val_accuracy: 0.1979\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9476 - accuracy: 0.1873 - val_loss: 2.9236 - val_accuracy: 0.1941\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9461 - accuracy: 0.1873 - val_loss: 2.9132 - val_accuracy: 0.1951\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9414 - accuracy: 0.1897 - val_loss: 2.9177 - val_accuracy: 0.1969\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9401 - accuracy: 0.1885 - val_loss: 2.9200 - val_accuracy: 0.1927\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9373 - accuracy: 0.1890 - val_loss: 2.9154 - val_accuracy: 0.1963\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9367 - accuracy: 0.1908 - val_loss: 2.9103 - val_accuracy: 0.1972\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9345 - accuracy: 0.1913 - val_loss: 2.9262 - val_accuracy: 0.1960\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9328 - accuracy: 0.1904 - val_loss: 2.9093 - val_accuracy: 0.1961\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9313 - accuracy: 0.1904 - val_loss: 2.9045 - val_accuracy: 0.1973\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9295 - accuracy: 0.1931 - val_loss: 2.9038 - val_accuracy: 0.1970\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9302 - accuracy: 0.1901 - val_loss: 2.9138 - val_accuracy: 0.1961\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9269 - accuracy: 0.1916 - val_loss: 2.9048 - val_accuracy: 0.1970\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9274 - accuracy: 0.1913 - val_loss: 2.9121 - val_accuracy: 0.1941\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9267 - accuracy: 0.1905 - val_loss: 2.9047 - val_accuracy: 0.1979\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9257 - accuracy: 0.1920 - val_loss: 2.9023 - val_accuracy: 0.1961\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9262 - accuracy: 0.1914 - val_loss: 2.9009 - val_accuracy: 0.1993\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9252 - accuracy: 0.1903 - val_loss: 2.9073 - val_accuracy: 0.1963\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9231 - accuracy: 0.1917 - val_loss: 2.9047 - val_accuracy: 0.1963\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9231 - accuracy: 0.1928 - val_loss: 2.9037 - val_accuracy: 0.1998\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9234 - accuracy: 0.1913 - val_loss: 2.9016 - val_accuracy: 0.1994\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9250 - accuracy: 0.1910 - val_loss: 2.9006 - val_accuracy: 0.1977\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9230 - accuracy: 0.1930 - val_loss: 2.9082 - val_accuracy: 0.1966\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9240 - accuracy: 0.1915 - val_loss: 2.9051 - val_accuracy: 0.1987\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9218 - accuracy: 0.1934 - val_loss: 2.9100 - val_accuracy: 0.1961\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9204 - accuracy: 0.1926 - val_loss: 2.9050 - val_accuracy: 0.2026\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9228 - accuracy: 0.1927 - val_loss: 2.9026 - val_accuracy: 0.1942\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9201 - accuracy: 0.1926 - val_loss: 2.9015 - val_accuracy: 0.1983\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9230 - accuracy: 0.1924 - val_loss: 2.9032 - val_accuracy: 0.1960\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9224 - accuracy: 0.1931 - val_loss: 2.9003 - val_accuracy: 0.1990\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9213 - accuracy: 0.1941 - val_loss: 2.9005 - val_accuracy: 0.1961\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9203 - accuracy: 0.1921 - val_loss: 2.9044 - val_accuracy: 0.1971\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9205 - accuracy: 0.1938 - val_loss: 2.9009 - val_accuracy: 0.1994\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9215 - accuracy: 0.1928 - val_loss: 2.9053 - val_accuracy: 0.1986\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9201 - accuracy: 0.1933 - val_loss: 2.9017 - val_accuracy: 0.1969\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9208 - accuracy: 0.1929 - val_loss: 2.9037 - val_accuracy: 0.1982\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9187 - accuracy: 0.1942 - val_loss: 2.9031 - val_accuracy: 0.1996\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9203 - accuracy: 0.1929 - val_loss: 2.9053 - val_accuracy: 0.1968\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9215 - accuracy: 0.1938 - val_loss: 2.9006 - val_accuracy: 0.1983\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9188 - accuracy: 0.1924 - val_loss: 2.9008 - val_accuracy: 0.1963\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9201 - accuracy: 0.1928 - val_loss: 2.9030 - val_accuracy: 0.2004\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9201 - accuracy: 0.1915 - val_loss: 2.9070 - val_accuracy: 0.1973\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9213 - accuracy: 0.1926 - val_loss: 2.9051 - val_accuracy: 0.1983\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9215 - accuracy: 0.1917 - val_loss: 2.9011 - val_accuracy: 0.2006\n",
            "Test Accuracy: 20.064440369606018\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1989 - accuracy: 0.1561 - val_loss: 2.9874 - val_accuracy: 0.1834\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 3.0106 - accuracy: 0.1799 - val_loss: 2.9423 - val_accuracy: 0.1985\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9789 - accuracy: 0.1811 - val_loss: 2.9336 - val_accuracy: 0.1980\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9616 - accuracy: 0.1845 - val_loss: 2.9120 - val_accuracy: 0.1939\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9491 - accuracy: 0.1817 - val_loss: 2.9137 - val_accuracy: 0.1965\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9460 - accuracy: 0.1866 - val_loss: 2.9115 - val_accuracy: 0.1967\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9408 - accuracy: 0.1854 - val_loss: 2.9162 - val_accuracy: 0.1963\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9351 - accuracy: 0.1883 - val_loss: 2.9033 - val_accuracy: 0.1942\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9321 - accuracy: 0.1881 - val_loss: 2.9039 - val_accuracy: 0.2009\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9290 - accuracy: 0.1903 - val_loss: 2.9027 - val_accuracy: 0.1974\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9277 - accuracy: 0.1909 - val_loss: 2.9023 - val_accuracy: 0.2003\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9258 - accuracy: 0.1908 - val_loss: 2.9065 - val_accuracy: 0.1915\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9246 - accuracy: 0.1909 - val_loss: 2.8999 - val_accuracy: 0.1992\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9256 - accuracy: 0.1886 - val_loss: 2.8983 - val_accuracy: 0.2002\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9217 - accuracy: 0.1913 - val_loss: 2.8986 - val_accuracy: 0.1979\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9233 - accuracy: 0.1903 - val_loss: 2.9008 - val_accuracy: 0.1979\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9199 - accuracy: 0.1914 - val_loss: 2.9021 - val_accuracy: 0.1959\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9215 - accuracy: 0.1912 - val_loss: 2.8990 - val_accuracy: 0.1984\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9177 - accuracy: 0.1912 - val_loss: 2.9032 - val_accuracy: 0.2010\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9194 - accuracy: 0.1902 - val_loss: 2.8960 - val_accuracy: 0.1987\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9176 - accuracy: 0.1923 - val_loss: 2.9012 - val_accuracy: 0.1988\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9177 - accuracy: 0.1916 - val_loss: 2.9002 - val_accuracy: 0.1968\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9170 - accuracy: 0.1912 - val_loss: 2.8960 - val_accuracy: 0.2012\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9146 - accuracy: 0.1927 - val_loss: 2.8990 - val_accuracy: 0.2005\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9153 - accuracy: 0.1912 - val_loss: 2.9019 - val_accuracy: 0.2001\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9149 - accuracy: 0.1919 - val_loss: 2.8958 - val_accuracy: 0.2009\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9133 - accuracy: 0.1930 - val_loss: 2.8985 - val_accuracy: 0.2007\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9133 - accuracy: 0.1931 - val_loss: 2.8965 - val_accuracy: 0.2015\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9131 - accuracy: 0.1941 - val_loss: 2.8947 - val_accuracy: 0.2004\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9119 - accuracy: 0.1927 - val_loss: 2.8962 - val_accuracy: 0.2004\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9109 - accuracy: 0.1918 - val_loss: 2.9014 - val_accuracy: 0.2007\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9114 - accuracy: 0.1914 - val_loss: 2.8976 - val_accuracy: 0.2000\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9116 - accuracy: 0.1915 - val_loss: 2.8988 - val_accuracy: 0.1998\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9102 - accuracy: 0.1934 - val_loss: 2.8964 - val_accuracy: 0.2018\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9115 - accuracy: 0.1918 - val_loss: 2.9020 - val_accuracy: 0.1993\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9107 - accuracy: 0.1918 - val_loss: 2.8984 - val_accuracy: 0.2027\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9114 - accuracy: 0.1941 - val_loss: 2.9002 - val_accuracy: 0.1966\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9103 - accuracy: 0.1935 - val_loss: 2.9011 - val_accuracy: 0.2010\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9095 - accuracy: 0.1932 - val_loss: 2.8990 - val_accuracy: 0.2022\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9105 - accuracy: 0.1913 - val_loss: 2.8997 - val_accuracy: 0.2041\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9079 - accuracy: 0.1944 - val_loss: 2.8972 - val_accuracy: 0.2021\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9076 - accuracy: 0.1947 - val_loss: 2.9022 - val_accuracy: 0.1985\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9078 - accuracy: 0.1949 - val_loss: 2.8994 - val_accuracy: 0.2015\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9074 - accuracy: 0.1951 - val_loss: 2.9027 - val_accuracy: 0.2013\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 14ms/step - loss: 2.9084 - accuracy: 0.1932 - val_loss: 2.8958 - val_accuracy: 0.2015\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9094 - accuracy: 0.1935 - val_loss: 2.9014 - val_accuracy: 0.2012\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9069 - accuracy: 0.1951 - val_loss: 2.8993 - val_accuracy: 0.2007\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9074 - accuracy: 0.1936 - val_loss: 2.8979 - val_accuracy: 0.2028\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9091 - accuracy: 0.1926 - val_loss: 2.8978 - val_accuracy: 0.2012\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9063 - accuracy: 0.1952 - val_loss: 2.8998 - val_accuracy: 0.2034\n",
            "Test Accuracy: 20.337824523448944\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1640 - accuracy: 0.1602 - val_loss: 2.9761 - val_accuracy: 0.1811\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9871 - accuracy: 0.1823 - val_loss: 2.9289 - val_accuracy: 0.1969\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9551 - accuracy: 0.1864 - val_loss: 2.9105 - val_accuracy: 0.1983\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9429 - accuracy: 0.1906 - val_loss: 2.9110 - val_accuracy: 0.2018\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9354 - accuracy: 0.1911 - val_loss: 2.9076 - val_accuracy: 0.1951\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9352 - accuracy: 0.1931 - val_loss: 2.9009 - val_accuracy: 0.1980\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9293 - accuracy: 0.1953 - val_loss: 2.8991 - val_accuracy: 0.1988\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9285 - accuracy: 0.1945 - val_loss: 2.8966 - val_accuracy: 0.2010\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9238 - accuracy: 0.1947 - val_loss: 2.9040 - val_accuracy: 0.1996\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9238 - accuracy: 0.1945 - val_loss: 2.8971 - val_accuracy: 0.1986\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9211 - accuracy: 0.1958 - val_loss: 2.8953 - val_accuracy: 0.1998\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9212 - accuracy: 0.1951 - val_loss: 2.8952 - val_accuracy: 0.1977\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9186 - accuracy: 0.1937 - val_loss: 2.8923 - val_accuracy: 0.1977\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9197 - accuracy: 0.1940 - val_loss: 2.8938 - val_accuracy: 0.1997\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9150 - accuracy: 0.1933 - val_loss: 2.8938 - val_accuracy: 0.2005\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9150 - accuracy: 0.1962 - val_loss: 2.8956 - val_accuracy: 0.1992\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9123 - accuracy: 0.1963 - val_loss: 2.9039 - val_accuracy: 0.1961\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9118 - accuracy: 0.1963 - val_loss: 2.8920 - val_accuracy: 0.1997\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9098 - accuracy: 0.1947 - val_loss: 2.8904 - val_accuracy: 0.1995\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9070 - accuracy: 0.1975 - val_loss: 2.8906 - val_accuracy: 0.1996\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9081 - accuracy: 0.1981 - val_loss: 2.8886 - val_accuracy: 0.1999\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9061 - accuracy: 0.1984 - val_loss: 2.8912 - val_accuracy: 0.1991\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9066 - accuracy: 0.1970 - val_loss: 2.8860 - val_accuracy: 0.2004\n",
            "Epoch 24/50\n",
            "818/820 [============================>.] - ETA: 0s - loss: 2.9056 - accuracy: 0.1976Restoring model weights from the end of the best epoch: 4.\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9057 - accuracy: 0.1976 - val_loss: 2.8873 - val_accuracy: 0.2018\n",
            "Epoch 24: early stopping\n",
            "Test Accuracy: 20.181605219841003\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1454 - accuracy: 0.1551 - val_loss: 2.9850 - val_accuracy: 0.1962\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9955 - accuracy: 0.1792 - val_loss: 2.9399 - val_accuracy: 0.1846\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9699 - accuracy: 0.1829 - val_loss: 2.9146 - val_accuracy: 0.1980\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9492 - accuracy: 0.1900 - val_loss: 2.9037 - val_accuracy: 0.1933\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9381 - accuracy: 0.1929 - val_loss: 2.9085 - val_accuracy: 0.1973\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9323 - accuracy: 0.1922 - val_loss: 2.9013 - val_accuracy: 0.1967\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9299 - accuracy: 0.1916 - val_loss: 2.9029 - val_accuracy: 0.1985\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9277 - accuracy: 0.1896 - val_loss: 2.8992 - val_accuracy: 0.1944\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9199 - accuracy: 0.1911 - val_loss: 2.8953 - val_accuracy: 0.1986\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9147 - accuracy: 0.1908 - val_loss: 2.9052 - val_accuracy: 0.2013\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9140 - accuracy: 0.1928 - val_loss: 2.8939 - val_accuracy: 0.2031\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9113 - accuracy: 0.1921 - val_loss: 2.8929 - val_accuracy: 0.1951\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9075 - accuracy: 0.1925 - val_loss: 2.8860 - val_accuracy: 0.2001\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9088 - accuracy: 0.1921 - val_loss: 2.8972 - val_accuracy: 0.1971\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9073 - accuracy: 0.1935 - val_loss: 2.8872 - val_accuracy: 0.1991\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9066 - accuracy: 0.1937 - val_loss: 2.8898 - val_accuracy: 0.2009\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9056 - accuracy: 0.1949 - val_loss: 2.8849 - val_accuracy: 0.2027\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9047 - accuracy: 0.1947 - val_loss: 2.8864 - val_accuracy: 0.2012\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9046 - accuracy: 0.1947 - val_loss: 2.8909 - val_accuracy: 0.2040\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9025 - accuracy: 0.1955 - val_loss: 2.8902 - val_accuracy: 0.2029\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9030 - accuracy: 0.1941 - val_loss: 2.8934 - val_accuracy: 0.2012\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9023 - accuracy: 0.1944 - val_loss: 2.8912 - val_accuracy: 0.2008\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9011 - accuracy: 0.1946 - val_loss: 2.8924 - val_accuracy: 0.1994\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8983 - accuracy: 0.1974 - val_loss: 2.8933 - val_accuracy: 0.2035\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9001 - accuracy: 0.1937 - val_loss: 2.8869 - val_accuracy: 0.2008\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8984 - accuracy: 0.1965 - val_loss: 2.8936 - val_accuracy: 0.2042\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8970 - accuracy: 0.1966 - val_loss: 2.8879 - val_accuracy: 0.2020\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8982 - accuracy: 0.1965 - val_loss: 2.8892 - val_accuracy: 0.2034\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8958 - accuracy: 0.1958 - val_loss: 2.8960 - val_accuracy: 0.1942\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8942 - accuracy: 0.1970 - val_loss: 2.8916 - val_accuracy: 0.2005\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8964 - accuracy: 0.1955 - val_loss: 2.8922 - val_accuracy: 0.2006\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8971 - accuracy: 0.1955 - val_loss: 2.8942 - val_accuracy: 0.2007\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8951 - accuracy: 0.1957 - val_loss: 2.8904 - val_accuracy: 0.2037\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8946 - accuracy: 0.1965 - val_loss: 2.8948 - val_accuracy: 0.2007\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8923 - accuracy: 0.1968 - val_loss: 2.8920 - val_accuracy: 0.2031\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8944 - accuracy: 0.1975 - val_loss: 2.8973 - val_accuracy: 0.1971\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8925 - accuracy: 0.1974 - val_loss: 2.8918 - val_accuracy: 0.2040\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8923 - accuracy: 0.1942 - val_loss: 2.8999 - val_accuracy: 0.2021\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8923 - accuracy: 0.1980 - val_loss: 2.8961 - val_accuracy: 0.2006\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8900 - accuracy: 0.1993 - val_loss: 2.8893 - val_accuracy: 0.1999\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8911 - accuracy: 0.1981 - val_loss: 2.8911 - val_accuracy: 0.2022\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8930 - accuracy: 0.1986 - val_loss: 2.8926 - val_accuracy: 0.2025\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8902 - accuracy: 0.1981 - val_loss: 2.8941 - val_accuracy: 0.2056\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8895 - accuracy: 0.1993 - val_loss: 2.8913 - val_accuracy: 0.2042\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8911 - accuracy: 0.2016 - val_loss: 2.8963 - val_accuracy: 0.2033\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8912 - accuracy: 0.2005 - val_loss: 2.9045 - val_accuracy: 0.2023\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8901 - accuracy: 0.1999 - val_loss: 2.8914 - val_accuracy: 0.2046\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8876 - accuracy: 0.2000 - val_loss: 2.8993 - val_accuracy: 0.2045\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8916 - accuracy: 0.1985 - val_loss: 2.9032 - val_accuracy: 0.2015\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8895 - accuracy: 0.2015 - val_loss: 2.9004 - val_accuracy: 0.2013\n",
            "Test Accuracy: 20.13278603553772\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.2047 - accuracy: 0.1386 - val_loss: 3.0075 - val_accuracy: 0.1803\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 3.0200 - accuracy: 0.1723 - val_loss: 2.9753 - val_accuracy: 0.1874\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9841 - accuracy: 0.1838 - val_loss: 2.9327 - val_accuracy: 0.1963\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9582 - accuracy: 0.1886 - val_loss: 2.9344 - val_accuracy: 0.1947\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9513 - accuracy: 0.1885 - val_loss: 2.9114 - val_accuracy: 0.1971\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9459 - accuracy: 0.1876 - val_loss: 2.9104 - val_accuracy: 0.1973\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9389 - accuracy: 0.1870 - val_loss: 2.9108 - val_accuracy: 0.1965\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9364 - accuracy: 0.1877 - val_loss: 2.9118 - val_accuracy: 0.1950\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9343 - accuracy: 0.1880 - val_loss: 2.9046 - val_accuracy: 0.1951\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9305 - accuracy: 0.1876 - val_loss: 2.9044 - val_accuracy: 0.1975\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9294 - accuracy: 0.1882 - val_loss: 2.9097 - val_accuracy: 0.1946\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9278 - accuracy: 0.1898 - val_loss: 2.9037 - val_accuracy: 0.1964\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9269 - accuracy: 0.1888 - val_loss: 2.8991 - val_accuracy: 0.1998\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9231 - accuracy: 0.1897 - val_loss: 2.9053 - val_accuracy: 0.1947\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9180 - accuracy: 0.1908 - val_loss: 2.9020 - val_accuracy: 0.1988\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9160 - accuracy: 0.1902 - val_loss: 2.9009 - val_accuracy: 0.1980\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9148 - accuracy: 0.1913 - val_loss: 2.8943 - val_accuracy: 0.1975\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9134 - accuracy: 0.1929 - val_loss: 2.8987 - val_accuracy: 0.1994\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9124 - accuracy: 0.1926 - val_loss: 2.8951 - val_accuracy: 0.1989\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9093 - accuracy: 0.1928 - val_loss: 2.8890 - val_accuracy: 0.2003\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9073 - accuracy: 0.1964 - val_loss: 2.8943 - val_accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9069 - accuracy: 0.1929 - val_loss: 2.8883 - val_accuracy: 0.1978\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9056 - accuracy: 0.1927 - val_loss: 2.8917 - val_accuracy: 0.1999\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9032 - accuracy: 0.1947 - val_loss: 2.8903 - val_accuracy: 0.2004\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9032 - accuracy: 0.1933 - val_loss: 2.8912 - val_accuracy: 0.1987\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9038 - accuracy: 0.1949 - val_loss: 2.8877 - val_accuracy: 0.2004\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9010 - accuracy: 0.1958 - val_loss: 2.8894 - val_accuracy: 0.2004\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9018 - accuracy: 0.1961 - val_loss: 2.8863 - val_accuracy: 0.2002\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8987 - accuracy: 0.1956 - val_loss: 2.8900 - val_accuracy: 0.2000\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8987 - accuracy: 0.1956 - val_loss: 2.8924 - val_accuracy: 0.1992\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8981 - accuracy: 0.1967 - val_loss: 2.8858 - val_accuracy: 0.1971\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8969 - accuracy: 0.1964 - val_loss: 2.8879 - val_accuracy: 0.1999\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8941 - accuracy: 0.1962 - val_loss: 2.8893 - val_accuracy: 0.2006\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8932 - accuracy: 0.1964 - val_loss: 2.8891 - val_accuracy: 0.2017\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8892 - accuracy: 0.1976 - val_loss: 2.8824 - val_accuracy: 0.2010\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8906 - accuracy: 0.1995 - val_loss: 2.8878 - val_accuracy: 0.2001\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8902 - accuracy: 0.1990 - val_loss: 2.8867 - val_accuracy: 0.2004\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8885 - accuracy: 0.1999 - val_loss: 2.8893 - val_accuracy: 0.2008\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8860 - accuracy: 0.2009 - val_loss: 2.8807 - val_accuracy: 0.2036\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8848 - accuracy: 0.2013 - val_loss: 2.8850 - val_accuracy: 0.1999\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8871 - accuracy: 0.2004 - val_loss: 2.8927 - val_accuracy: 0.2020\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8867 - accuracy: 0.2015 - val_loss: 2.8856 - val_accuracy: 0.2032\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8853 - accuracy: 0.1996 - val_loss: 2.8802 - val_accuracy: 0.2034\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8828 - accuracy: 0.2024 - val_loss: 2.8856 - val_accuracy: 0.2019\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8826 - accuracy: 0.2016 - val_loss: 2.8852 - val_accuracy: 0.2039\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8824 - accuracy: 0.2008 - val_loss: 2.8862 - val_accuracy: 0.2016\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8844 - accuracy: 0.2014 - val_loss: 2.8923 - val_accuracy: 0.2019\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8820 - accuracy: 0.2006 - val_loss: 2.8808 - val_accuracy: 0.2041\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8820 - accuracy: 0.2019 - val_loss: 2.8909 - val_accuracy: 0.2047\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8795 - accuracy: 0.2025 - val_loss: 2.8969 - val_accuracy: 0.2038\n",
            "Test Accuracy: 20.3768789768219\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.2388 - accuracy: 0.1362 - val_loss: 3.0218 - val_accuracy: 0.1674\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 3.0220 - accuracy: 0.1753 - val_loss: 2.9476 - val_accuracy: 0.1871\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9798 - accuracy: 0.1827 - val_loss: 2.9357 - val_accuracy: 0.1957\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9628 - accuracy: 0.1856 - val_loss: 2.9216 - val_accuracy: 0.1964\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9592 - accuracy: 0.1856 - val_loss: 2.9251 - val_accuracy: 0.1914\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9536 - accuracy: 0.1864 - val_loss: 2.9201 - val_accuracy: 0.1939\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9480 - accuracy: 0.1866 - val_loss: 2.9110 - val_accuracy: 0.1968\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9431 - accuracy: 0.1876 - val_loss: 2.9087 - val_accuracy: 0.1972\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9376 - accuracy: 0.1893 - val_loss: 2.9048 - val_accuracy: 0.1984\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9329 - accuracy: 0.1888 - val_loss: 2.9065 - val_accuracy: 0.1953\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9312 - accuracy: 0.1890 - val_loss: 2.9011 - val_accuracy: 0.1976\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9268 - accuracy: 0.1912 - val_loss: 2.8986 - val_accuracy: 0.2002\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9243 - accuracy: 0.1911 - val_loss: 2.8989 - val_accuracy: 0.1972\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9236 - accuracy: 0.1896 - val_loss: 2.8992 - val_accuracy: 0.1977\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9227 - accuracy: 0.1922 - val_loss: 2.9026 - val_accuracy: 0.2006\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9204 - accuracy: 0.1914 - val_loss: 2.8979 - val_accuracy: 0.1991\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9193 - accuracy: 0.1938 - val_loss: 2.8978 - val_accuracy: 0.1933\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9178 - accuracy: 0.1908 - val_loss: 2.9111 - val_accuracy: 0.1994\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9156 - accuracy: 0.1935 - val_loss: 2.8936 - val_accuracy: 0.1986\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9142 - accuracy: 0.1938 - val_loss: 2.8928 - val_accuracy: 0.1997\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9143 - accuracy: 0.1929 - val_loss: 2.9001 - val_accuracy: 0.2008\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9130 - accuracy: 0.1928 - val_loss: 2.8949 - val_accuracy: 0.1993\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9124 - accuracy: 0.1926 - val_loss: 2.9028 - val_accuracy: 0.2025\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9097 - accuracy: 0.1945 - val_loss: 2.8925 - val_accuracy: 0.2014\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9098 - accuracy: 0.1956 - val_loss: 2.8955 - val_accuracy: 0.2010\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9091 - accuracy: 0.1964 - val_loss: 2.8882 - val_accuracy: 0.2005\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9053 - accuracy: 0.1973 - val_loss: 2.8894 - val_accuracy: 0.2032\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9036 - accuracy: 0.1961 - val_loss: 2.8947 - val_accuracy: 0.2007\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9050 - accuracy: 0.1977 - val_loss: 2.8912 - val_accuracy: 0.2005\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9043 - accuracy: 0.1970 - val_loss: 2.8921 - val_accuracy: 0.2002\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9028 - accuracy: 0.1980 - val_loss: 2.8895 - val_accuracy: 0.2008\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9042 - accuracy: 0.1957 - val_loss: 2.8966 - val_accuracy: 0.2011\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9010 - accuracy: 0.1956 - val_loss: 2.8964 - val_accuracy: 0.2008\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9027 - accuracy: 0.1982 - val_loss: 2.8916 - val_accuracy: 0.2007\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9043 - accuracy: 0.1973 - val_loss: 2.8948 - val_accuracy: 0.2001\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8994 - accuracy: 0.1967 - val_loss: 2.8962 - val_accuracy: 0.2006\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9003 - accuracy: 0.1956 - val_loss: 2.8947 - val_accuracy: 0.2013\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9004 - accuracy: 0.1986 - val_loss: 2.8933 - val_accuracy: 0.2005\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9000 - accuracy: 0.1975 - val_loss: 2.8929 - val_accuracy: 0.2012\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9019 - accuracy: 0.1976 - val_loss: 2.8941 - val_accuracy: 0.2027\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9003 - accuracy: 0.1958 - val_loss: 2.8894 - val_accuracy: 0.2014\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8984 - accuracy: 0.1969 - val_loss: 2.8949 - val_accuracy: 0.2009\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8986 - accuracy: 0.1970 - val_loss: 2.8966 - val_accuracy: 0.2007\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8995 - accuracy: 0.1974 - val_loss: 2.8988 - val_accuracy: 0.2001\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8990 - accuracy: 0.1962 - val_loss: 2.8991 - val_accuracy: 0.2011\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8987 - accuracy: 0.1970 - val_loss: 2.8942 - val_accuracy: 0.2007\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9003 - accuracy: 0.1964 - val_loss: 2.8977 - val_accuracy: 0.2035\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8998 - accuracy: 0.1971 - val_loss: 2.8977 - val_accuracy: 0.2015\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8975 - accuracy: 0.1982 - val_loss: 2.8971 - val_accuracy: 0.2014\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8983 - accuracy: 0.1963 - val_loss: 2.8921 - val_accuracy: 0.2008\n",
            "Test Accuracy: 20.083968341350555\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.2161 - accuracy: 0.1231 - val_loss: 3.0007 - val_accuracy: 0.1541\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0307 - accuracy: 0.1607 - val_loss: 2.9643 - val_accuracy: 0.1882\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0014 - accuracy: 0.1791 - val_loss: 2.9519 - val_accuracy: 0.1874\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9893 - accuracy: 0.1818 - val_loss: 2.9636 - val_accuracy: 0.1858\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9840 - accuracy: 0.1826 - val_loss: 2.9434 - val_accuracy: 0.1878\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9798 - accuracy: 0.1822 - val_loss: 2.9432 - val_accuracy: 0.1959\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9745 - accuracy: 0.1836 - val_loss: 2.9431 - val_accuracy: 0.1932\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9692 - accuracy: 0.1831 - val_loss: 2.9393 - val_accuracy: 0.1908\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9640 - accuracy: 0.1816 - val_loss: 2.9460 - val_accuracy: 0.1870\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9512 - accuracy: 0.1863 - val_loss: 2.9265 - val_accuracy: 0.1902\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9425 - accuracy: 0.1892 - val_loss: 2.9172 - val_accuracy: 0.1971\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9386 - accuracy: 0.1889 - val_loss: 2.9160 - val_accuracy: 0.1973\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9337 - accuracy: 0.1885 - val_loss: 2.9115 - val_accuracy: 0.1928\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9297 - accuracy: 0.1894 - val_loss: 2.9177 - val_accuracy: 0.1917\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9269 - accuracy: 0.1902 - val_loss: 2.9017 - val_accuracy: 0.1977\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9230 - accuracy: 0.1907 - val_loss: 2.9067 - val_accuracy: 0.1992\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9201 - accuracy: 0.1915 - val_loss: 2.9048 - val_accuracy: 0.2004\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9179 - accuracy: 0.1917 - val_loss: 2.8999 - val_accuracy: 0.1997\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9166 - accuracy: 0.1904 - val_loss: 2.8975 - val_accuracy: 0.2005\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9136 - accuracy: 0.1920 - val_loss: 2.8951 - val_accuracy: 0.2006\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9121 - accuracy: 0.1925 - val_loss: 2.8920 - val_accuracy: 0.1992\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9105 - accuracy: 0.1929 - val_loss: 2.8991 - val_accuracy: 0.1959\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9090 - accuracy: 0.1937 - val_loss: 2.8983 - val_accuracy: 0.2005\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9053 - accuracy: 0.1966 - val_loss: 2.8955 - val_accuracy: 0.2031\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9043 - accuracy: 0.1962 - val_loss: 2.8959 - val_accuracy: 0.2003\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9032 - accuracy: 0.1971 - val_loss: 2.8910 - val_accuracy: 0.2006\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9031 - accuracy: 0.1974 - val_loss: 2.8909 - val_accuracy: 0.1989\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9024 - accuracy: 0.1968 - val_loss: 2.8954 - val_accuracy: 0.2033\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9018 - accuracy: 0.1971 - val_loss: 2.9007 - val_accuracy: 0.2004\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9015 - accuracy: 0.1968 - val_loss: 2.8936 - val_accuracy: 0.1998\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9012 - accuracy: 0.1992 - val_loss: 2.8981 - val_accuracy: 0.2030\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8985 - accuracy: 0.1981 - val_loss: 2.8942 - val_accuracy: 0.2015\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8980 - accuracy: 0.1990 - val_loss: 2.8991 - val_accuracy: 0.2031\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8958 - accuracy: 0.1977 - val_loss: 2.8910 - val_accuracy: 0.2031\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8971 - accuracy: 0.1972 - val_loss: 2.8881 - val_accuracy: 0.2007\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8966 - accuracy: 0.1969 - val_loss: 2.8888 - val_accuracy: 0.2025\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8951 - accuracy: 0.1971 - val_loss: 2.8859 - val_accuracy: 0.2010\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8918 - accuracy: 0.1957 - val_loss: 2.8856 - val_accuracy: 0.2033\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8927 - accuracy: 0.1969 - val_loss: 2.8885 - val_accuracy: 0.2025\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8911 - accuracy: 0.1954 - val_loss: 2.8847 - val_accuracy: 0.2023\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8903 - accuracy: 0.1979 - val_loss: 2.8863 - val_accuracy: 0.2027\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8889 - accuracy: 0.1996 - val_loss: 2.8936 - val_accuracy: 0.2028\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8880 - accuracy: 0.1987 - val_loss: 2.8931 - val_accuracy: 0.2035\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8881 - accuracy: 0.2007 - val_loss: 2.8891 - val_accuracy: 0.1992\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8852 - accuracy: 0.2004 - val_loss: 2.8937 - val_accuracy: 0.2012\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8869 - accuracy: 0.1982 - val_loss: 2.8959 - val_accuracy: 0.2032\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8866 - accuracy: 0.1985 - val_loss: 2.8846 - val_accuracy: 0.2035\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8855 - accuracy: 0.2006 - val_loss: 2.8924 - val_accuracy: 0.2037\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8841 - accuracy: 0.2002 - val_loss: 2.8878 - val_accuracy: 0.2035\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8856 - accuracy: 0.1994 - val_loss: 2.8889 - val_accuracy: 0.2020\n",
            "Test Accuracy: 20.20113319158554\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1683 - accuracy: 0.1583 - val_loss: 2.9696 - val_accuracy: 0.1941\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9907 - accuracy: 0.1800 - val_loss: 2.9357 - val_accuracy: 0.1939\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9623 - accuracy: 0.1831 - val_loss: 2.9156 - val_accuracy: 0.1938\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9498 - accuracy: 0.1874 - val_loss: 2.9188 - val_accuracy: 0.1947\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9468 - accuracy: 0.1890 - val_loss: 2.9111 - val_accuracy: 0.1950\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9416 - accuracy: 0.1916 - val_loss: 2.9091 - val_accuracy: 0.1969\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9349 - accuracy: 0.1918 - val_loss: 2.9083 - val_accuracy: 0.1995\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9327 - accuracy: 0.1929 - val_loss: 2.9053 - val_accuracy: 0.1973\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9281 - accuracy: 0.1942 - val_loss: 2.9125 - val_accuracy: 0.1968\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9259 - accuracy: 0.1937 - val_loss: 2.9111 - val_accuracy: 0.1963\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9203 - accuracy: 0.1932 - val_loss: 2.8986 - val_accuracy: 0.2011\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9197 - accuracy: 0.1944 - val_loss: 2.9023 - val_accuracy: 0.1974\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9174 - accuracy: 0.1952 - val_loss: 2.8975 - val_accuracy: 0.1991\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9144 - accuracy: 0.1966 - val_loss: 2.8985 - val_accuracy: 0.1985\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9154 - accuracy: 0.1941 - val_loss: 2.8979 - val_accuracy: 0.1991\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9112 - accuracy: 0.1961 - val_loss: 2.9032 - val_accuracy: 0.1994\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9106 - accuracy: 0.1961 - val_loss: 2.8933 - val_accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9106 - accuracy: 0.1948 - val_loss: 2.8958 - val_accuracy: 0.1982\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9081 - accuracy: 0.1990 - val_loss: 2.8949 - val_accuracy: 0.1994\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9083 - accuracy: 0.1959 - val_loss: 2.8984 - val_accuracy: 0.1974\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9066 - accuracy: 0.1978 - val_loss: 2.8998 - val_accuracy: 0.1984\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9058 - accuracy: 0.1979 - val_loss: 2.8940 - val_accuracy: 0.1961\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9031 - accuracy: 0.1967 - val_loss: 2.8953 - val_accuracy: 0.2022\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9038 - accuracy: 0.1961 - val_loss: 2.8948 - val_accuracy: 0.1981\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9031 - accuracy: 0.1960 - val_loss: 2.8918 - val_accuracy: 0.1985\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9022 - accuracy: 0.1977 - val_loss: 2.8878 - val_accuracy: 0.1984\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9012 - accuracy: 0.1972 - val_loss: 2.8938 - val_accuracy: 0.2018\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8986 - accuracy: 0.1969 - val_loss: 2.8937 - val_accuracy: 0.2028\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8985 - accuracy: 0.1975 - val_loss: 2.8950 - val_accuracy: 0.2023\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8990 - accuracy: 0.1974 - val_loss: 2.8904 - val_accuracy: 0.1993\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8994 - accuracy: 0.1982 - val_loss: 2.8910 - val_accuracy: 0.2031\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8990 - accuracy: 0.1975 - val_loss: 2.8916 - val_accuracy: 0.2004\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8986 - accuracy: 0.1969 - val_loss: 2.8960 - val_accuracy: 0.1982\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8966 - accuracy: 0.1986 - val_loss: 2.8905 - val_accuracy: 0.2004\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8983 - accuracy: 0.1978 - val_loss: 2.8958 - val_accuracy: 0.2012\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8952 - accuracy: 0.1976 - val_loss: 2.8889 - val_accuracy: 0.2001\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8956 - accuracy: 0.1976 - val_loss: 2.9056 - val_accuracy: 0.2024\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8971 - accuracy: 0.1971 - val_loss: 2.9005 - val_accuracy: 0.2025\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8945 - accuracy: 0.1991 - val_loss: 2.8967 - val_accuracy: 0.2027\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8951 - accuracy: 0.1973 - val_loss: 2.8932 - val_accuracy: 0.2032\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8922 - accuracy: 0.2000 - val_loss: 2.8950 - val_accuracy: 0.2032\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8936 - accuracy: 0.1984 - val_loss: 2.9031 - val_accuracy: 0.2004\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8953 - accuracy: 0.1970 - val_loss: 2.8962 - val_accuracy: 0.2026\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8963 - accuracy: 0.1975 - val_loss: 2.8961 - val_accuracy: 0.2026\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8924 - accuracy: 0.1995 - val_loss: 2.8979 - val_accuracy: 0.2010\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8919 - accuracy: 0.1998 - val_loss: 2.8902 - val_accuracy: 0.2006\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8920 - accuracy: 0.1987 - val_loss: 2.8980 - val_accuracy: 0.2010\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8913 - accuracy: 0.1982 - val_loss: 2.8927 - val_accuracy: 0.2006\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8908 - accuracy: 0.1992 - val_loss: 2.8990 - val_accuracy: 0.2030\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8924 - accuracy: 0.1979 - val_loss: 2.8996 - val_accuracy: 0.2028\n",
            "Test Accuracy: 20.27924209833145\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1820 - accuracy: 0.1602 - val_loss: 2.9666 - val_accuracy: 0.1902\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9979 - accuracy: 0.1844 - val_loss: 2.9359 - val_accuracy: 0.1968\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9687 - accuracy: 0.1872 - val_loss: 2.9454 - val_accuracy: 0.1901\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9547 - accuracy: 0.1847 - val_loss: 2.9100 - val_accuracy: 0.2031\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9479 - accuracy: 0.1835 - val_loss: 2.9128 - val_accuracy: 0.1931\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9434 - accuracy: 0.1887 - val_loss: 2.9074 - val_accuracy: 0.1986\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9379 - accuracy: 0.1867 - val_loss: 2.9203 - val_accuracy: 0.2004\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9326 - accuracy: 0.1889 - val_loss: 2.9031 - val_accuracy: 0.1962\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9334 - accuracy: 0.1872 - val_loss: 2.9080 - val_accuracy: 0.1985\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9287 - accuracy: 0.1913 - val_loss: 2.8970 - val_accuracy: 0.1982\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9270 - accuracy: 0.1892 - val_loss: 2.8988 - val_accuracy: 0.1988\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9252 - accuracy: 0.1872 - val_loss: 2.9013 - val_accuracy: 0.1946\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9244 - accuracy: 0.1893 - val_loss: 2.9029 - val_accuracy: 0.1954\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9233 - accuracy: 0.1880 - val_loss: 2.9032 - val_accuracy: 0.1967\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9205 - accuracy: 0.1903 - val_loss: 2.8938 - val_accuracy: 0.1992\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9211 - accuracy: 0.1880 - val_loss: 2.9024 - val_accuracy: 0.1971\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9203 - accuracy: 0.1882 - val_loss: 2.8972 - val_accuracy: 0.1979\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9186 - accuracy: 0.1888 - val_loss: 2.9002 - val_accuracy: 0.1964\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9174 - accuracy: 0.1889 - val_loss: 2.8928 - val_accuracy: 0.1984\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9170 - accuracy: 0.1898 - val_loss: 2.8936 - val_accuracy: 0.1983\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9160 - accuracy: 0.1912 - val_loss: 2.8934 - val_accuracy: 0.1989\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9187 - accuracy: 0.1907 - val_loss: 2.8956 - val_accuracy: 0.1966\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9155 - accuracy: 0.1904 - val_loss: 2.8926 - val_accuracy: 0.1972\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - ETA: 0s - loss: 2.9159 - accuracy: 0.1897Restoring model weights from the end of the best epoch: 4.\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9159 - accuracy: 0.1897 - val_loss: 2.8901 - val_accuracy: 0.1995\n",
            "Epoch 24: early stopping\n",
            "Test Accuracy: 20.308533310890198\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 16ms/step - loss: 3.1772 - accuracy: 0.1591 - val_loss: 2.9535 - val_accuracy: 0.1915\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9761 - accuracy: 0.1847 - val_loss: 2.9358 - val_accuracy: 0.1895\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9519 - accuracy: 0.1894 - val_loss: 2.9284 - val_accuracy: 0.1962\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9411 - accuracy: 0.1892 - val_loss: 2.9115 - val_accuracy: 0.1980\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9345 - accuracy: 0.1929 - val_loss: 2.9125 - val_accuracy: 0.1928\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9291 - accuracy: 0.1945 - val_loss: 2.9078 - val_accuracy: 0.1963\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9252 - accuracy: 0.1943 - val_loss: 2.8983 - val_accuracy: 0.1952\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9223 - accuracy: 0.1942 - val_loss: 2.8956 - val_accuracy: 0.1958\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9165 - accuracy: 0.1934 - val_loss: 2.9053 - val_accuracy: 0.1972\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9158 - accuracy: 0.1948 - val_loss: 2.8989 - val_accuracy: 0.1991\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9139 - accuracy: 0.1945 - val_loss: 2.8968 - val_accuracy: 0.1987\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9094 - accuracy: 0.1956 - val_loss: 2.8925 - val_accuracy: 0.1986\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9094 - accuracy: 0.1979 - val_loss: 2.8878 - val_accuracy: 0.1938\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9079 - accuracy: 0.1977 - val_loss: 2.8874 - val_accuracy: 0.2014\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9063 - accuracy: 0.1985 - val_loss: 2.8885 - val_accuracy: 0.1990\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9066 - accuracy: 0.1968 - val_loss: 2.8934 - val_accuracy: 0.1966\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9052 - accuracy: 0.1978 - val_loss: 2.8851 - val_accuracy: 0.2003\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9025 - accuracy: 0.1972 - val_loss: 2.8872 - val_accuracy: 0.1974\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8986 - accuracy: 0.1975 - val_loss: 2.8880 - val_accuracy: 0.1984\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8954 - accuracy: 0.1974 - val_loss: 2.8838 - val_accuracy: 0.1990\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8972 - accuracy: 0.1982 - val_loss: 2.8849 - val_accuracy: 0.2021\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8968 - accuracy: 0.1974 - val_loss: 2.8815 - val_accuracy: 0.1988\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8930 - accuracy: 0.1983 - val_loss: 2.8822 - val_accuracy: 0.2006\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8914 - accuracy: 0.1968 - val_loss: 2.8850 - val_accuracy: 0.1958\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8889 - accuracy: 0.2007 - val_loss: 2.8852 - val_accuracy: 0.1995\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8918 - accuracy: 0.1987 - val_loss: 2.8814 - val_accuracy: 0.2031\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8878 - accuracy: 0.2004 - val_loss: 2.8795 - val_accuracy: 0.2023\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8910 - accuracy: 0.2004 - val_loss: 2.8782 - val_accuracy: 0.2011\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8884 - accuracy: 0.1992 - val_loss: 2.8840 - val_accuracy: 0.1989\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8874 - accuracy: 0.2005 - val_loss: 2.8832 - val_accuracy: 0.2022\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8863 - accuracy: 0.1982 - val_loss: 2.8794 - val_accuracy: 0.2024\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8858 - accuracy: 0.1991 - val_loss: 2.8783 - val_accuracy: 0.2034\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8840 - accuracy: 0.1998 - val_loss: 2.8811 - val_accuracy: 0.2002\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8861 - accuracy: 0.1986 - val_loss: 2.8856 - val_accuracy: 0.2014\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8847 - accuracy: 0.1998 - val_loss: 2.8797 - val_accuracy: 0.2009\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8866 - accuracy: 0.1994 - val_loss: 2.8794 - val_accuracy: 0.2006\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8842 - accuracy: 0.1999 - val_loss: 2.8776 - val_accuracy: 0.2003\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8850 - accuracy: 0.1986 - val_loss: 2.8805 - val_accuracy: 0.2004\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8836 - accuracy: 0.1988 - val_loss: 2.8810 - val_accuracy: 0.2008\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8816 - accuracy: 0.2013 - val_loss: 2.8825 - val_accuracy: 0.2051\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8815 - accuracy: 0.2015 - val_loss: 2.8783 - val_accuracy: 0.2019\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8815 - accuracy: 0.1990 - val_loss: 2.8825 - val_accuracy: 0.2012\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8833 - accuracy: 0.1999 - val_loss: 2.8801 - val_accuracy: 0.2031\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8812 - accuracy: 0.2005 - val_loss: 2.8883 - val_accuracy: 0.2066\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8833 - accuracy: 0.2007 - val_loss: 2.8777 - val_accuracy: 0.2020\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8820 - accuracy: 0.2009 - val_loss: 2.8818 - val_accuracy: 0.2039\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8796 - accuracy: 0.1999 - val_loss: 2.8822 - val_accuracy: 0.2013\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8794 - accuracy: 0.1994 - val_loss: 2.8804 - val_accuracy: 0.2010\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8797 - accuracy: 0.2019 - val_loss: 2.8869 - val_accuracy: 0.2023\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8809 - accuracy: 0.1988 - val_loss: 2.8820 - val_accuracy: 0.2048\n",
            "Test Accuracy: 20.484280586242676\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.2275 - accuracy: 0.1318 - val_loss: 2.9786 - val_accuracy: 0.1917\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0003 - accuracy: 0.1834 - val_loss: 2.9439 - val_accuracy: 0.1922\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9733 - accuracy: 0.1846 - val_loss: 2.9305 - val_accuracy: 0.1944\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9559 - accuracy: 0.1856 - val_loss: 2.9283 - val_accuracy: 0.1967\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9458 - accuracy: 0.1868 - val_loss: 2.9396 - val_accuracy: 0.1921\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9426 - accuracy: 0.1873 - val_loss: 2.9094 - val_accuracy: 0.1950\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9385 - accuracy: 0.1890 - val_loss: 2.9118 - val_accuracy: 0.1966\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9364 - accuracy: 0.1895 - val_loss: 2.9134 - val_accuracy: 0.1959\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9348 - accuracy: 0.1909 - val_loss: 2.9030 - val_accuracy: 0.1966\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9350 - accuracy: 0.1876 - val_loss: 2.9041 - val_accuracy: 0.1975\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9318 - accuracy: 0.1903 - val_loss: 2.9112 - val_accuracy: 0.1979\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9311 - accuracy: 0.1890 - val_loss: 2.9050 - val_accuracy: 0.1974\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9280 - accuracy: 0.1897 - val_loss: 2.9035 - val_accuracy: 0.1954\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9279 - accuracy: 0.1901 - val_loss: 2.9079 - val_accuracy: 0.1944\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9267 - accuracy: 0.1900 - val_loss: 2.9045 - val_accuracy: 0.1959\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9247 - accuracy: 0.1902 - val_loss: 2.9013 - val_accuracy: 0.1944\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9207 - accuracy: 0.1925 - val_loss: 2.9029 - val_accuracy: 0.1957\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9218 - accuracy: 0.1919 - val_loss: 2.9025 - val_accuracy: 0.1984\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9205 - accuracy: 0.1916 - val_loss: 2.9036 - val_accuracy: 0.1980\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9244 - accuracy: 0.1900 - val_loss: 2.8993 - val_accuracy: 0.1996\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9210 - accuracy: 0.1909 - val_loss: 2.8998 - val_accuracy: 0.1992\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9207 - accuracy: 0.1921 - val_loss: 2.9037 - val_accuracy: 0.1995\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9191 - accuracy: 0.1909 - val_loss: 2.9010 - val_accuracy: 0.1968\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9200 - accuracy: 0.1898 - val_loss: 2.8990 - val_accuracy: 0.2008\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9215 - accuracy: 0.1903 - val_loss: 2.9036 - val_accuracy: 0.1978\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9176 - accuracy: 0.1903 - val_loss: 2.9008 - val_accuracy: 0.1979\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9156 - accuracy: 0.1929 - val_loss: 2.9015 - val_accuracy: 0.1987\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9157 - accuracy: 0.1909 - val_loss: 2.8968 - val_accuracy: 0.2013\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9158 - accuracy: 0.1911 - val_loss: 2.8971 - val_accuracy: 0.2002\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9133 - accuracy: 0.1923 - val_loss: 2.8952 - val_accuracy: 0.1988\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9130 - accuracy: 0.1933 - val_loss: 2.8931 - val_accuracy: 0.2009\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9117 - accuracy: 0.1930 - val_loss: 2.8946 - val_accuracy: 0.2004\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9079 - accuracy: 0.1948 - val_loss: 2.8922 - val_accuracy: 0.1994\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9069 - accuracy: 0.1943 - val_loss: 2.8985 - val_accuracy: 0.2004\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9076 - accuracy: 0.1961 - val_loss: 2.8955 - val_accuracy: 0.1955\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9055 - accuracy: 0.1982 - val_loss: 2.8938 - val_accuracy: 0.2004\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9057 - accuracy: 0.1957 - val_loss: 2.8932 - val_accuracy: 0.1986\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9052 - accuracy: 0.1959 - val_loss: 2.8903 - val_accuracy: 0.2020\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9052 - accuracy: 0.1967 - val_loss: 2.8895 - val_accuracy: 0.2020\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9044 - accuracy: 0.1975 - val_loss: 2.8909 - val_accuracy: 0.2008\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9030 - accuracy: 0.1981 - val_loss: 2.8943 - val_accuracy: 0.1994\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9014 - accuracy: 0.1973 - val_loss: 2.8935 - val_accuracy: 0.2010\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9017 - accuracy: 0.1973 - val_loss: 2.8905 - val_accuracy: 0.2021\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8984 - accuracy: 0.1971 - val_loss: 2.8903 - val_accuracy: 0.2009\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8951 - accuracy: 0.1972 - val_loss: 2.8890 - val_accuracy: 0.2011\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8946 - accuracy: 0.1963 - val_loss: 2.8880 - val_accuracy: 0.2020\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8941 - accuracy: 0.1969 - val_loss: 2.8893 - val_accuracy: 0.2012\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8959 - accuracy: 0.1958 - val_loss: 2.8860 - val_accuracy: 0.2021\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8955 - accuracy: 0.1968 - val_loss: 2.8900 - val_accuracy: 0.2024\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.8926 - accuracy: 0.1971 - val_loss: 2.8865 - val_accuracy: 0.2026\n",
            "Test Accuracy: 20.259715616703033\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.2366 - accuracy: 0.1425 - val_loss: 3.0433 - val_accuracy: 0.1599\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0270 - accuracy: 0.1725 - val_loss: 2.9608 - val_accuracy: 0.1953\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0030 - accuracy: 0.1803 - val_loss: 2.9672 - val_accuracy: 0.1910\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9926 - accuracy: 0.1805 - val_loss: 2.9424 - val_accuracy: 0.1959\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9758 - accuracy: 0.1839 - val_loss: 2.9256 - val_accuracy: 0.1971\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9556 - accuracy: 0.1872 - val_loss: 2.9163 - val_accuracy: 0.1953\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9522 - accuracy: 0.1875 - val_loss: 2.9177 - val_accuracy: 0.1973\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9468 - accuracy: 0.1886 - val_loss: 2.9224 - val_accuracy: 0.1968\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9457 - accuracy: 0.1901 - val_loss: 2.9154 - val_accuracy: 0.1974\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9421 - accuracy: 0.1895 - val_loss: 2.9135 - val_accuracy: 0.1935\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9400 - accuracy: 0.1891 - val_loss: 2.9127 - val_accuracy: 0.1977\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9395 - accuracy: 0.1901 - val_loss: 2.9176 - val_accuracy: 0.1982\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9378 - accuracy: 0.1892 - val_loss: 2.9153 - val_accuracy: 0.1936\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9349 - accuracy: 0.1901 - val_loss: 2.9089 - val_accuracy: 0.1995\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9365 - accuracy: 0.1907 - val_loss: 2.9120 - val_accuracy: 0.1984\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9319 - accuracy: 0.1921 - val_loss: 2.9112 - val_accuracy: 0.1964\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9299 - accuracy: 0.1898 - val_loss: 2.9088 - val_accuracy: 0.1982\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9294 - accuracy: 0.1919 - val_loss: 2.9121 - val_accuracy: 0.1976\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9267 - accuracy: 0.1907 - val_loss: 2.9099 - val_accuracy: 0.1995\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9246 - accuracy: 0.1922 - val_loss: 2.9025 - val_accuracy: 0.2008\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9254 - accuracy: 0.1940 - val_loss: 2.9002 - val_accuracy: 0.1949\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9236 - accuracy: 0.1935 - val_loss: 2.9030 - val_accuracy: 0.1972\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9247 - accuracy: 0.1930 - val_loss: 2.9014 - val_accuracy: 0.2011\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9218 - accuracy: 0.1934 - val_loss: 2.9022 - val_accuracy: 0.1965\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9221 - accuracy: 0.1915 - val_loss: 2.8967 - val_accuracy: 0.2013\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9226 - accuracy: 0.1942 - val_loss: 2.9007 - val_accuracy: 0.2023\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9185 - accuracy: 0.1944 - val_loss: 2.9008 - val_accuracy: 0.1989\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9191 - accuracy: 0.1948 - val_loss: 2.9039 - val_accuracy: 0.1953\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9204 - accuracy: 0.1943 - val_loss: 2.9022 - val_accuracy: 0.1991\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9169 - accuracy: 0.1969 - val_loss: 2.9078 - val_accuracy: 0.1998\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9168 - accuracy: 0.1956 - val_loss: 2.9033 - val_accuracy: 0.2006\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9175 - accuracy: 0.1939 - val_loss: 2.9023 - val_accuracy: 0.2031\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9156 - accuracy: 0.1951 - val_loss: 2.9071 - val_accuracy: 0.1965\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9179 - accuracy: 0.1942 - val_loss: 2.9022 - val_accuracy: 0.1994\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9190 - accuracy: 0.1943 - val_loss: 2.9048 - val_accuracy: 0.2002\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9170 - accuracy: 0.1961 - val_loss: 2.9025 - val_accuracy: 0.1994\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9147 - accuracy: 0.1955 - val_loss: 2.9004 - val_accuracy: 0.2023\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9143 - accuracy: 0.1953 - val_loss: 2.9032 - val_accuracy: 0.2007\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 12s 15ms/step - loss: 2.9138 - accuracy: 0.1975 - val_loss: 2.8990 - val_accuracy: 0.2007\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9157 - accuracy: 0.1955 - val_loss: 2.9014 - val_accuracy: 0.1993\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9129 - accuracy: 0.1948 - val_loss: 2.9032 - val_accuracy: 0.2022\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9151 - accuracy: 0.1950 - val_loss: 2.9042 - val_accuracy: 0.1994\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9127 - accuracy: 0.1972 - val_loss: 2.9099 - val_accuracy: 0.2003\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9098 - accuracy: 0.1978 - val_loss: 2.9066 - val_accuracy: 0.1971\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9077 - accuracy: 0.1959 - val_loss: 2.8969 - val_accuracy: 0.2019\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9060 - accuracy: 0.1965 - val_loss: 2.8967 - val_accuracy: 0.2006\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9076 - accuracy: 0.1974 - val_loss: 2.9050 - val_accuracy: 0.2012\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9058 - accuracy: 0.1971 - val_loss: 2.8986 - val_accuracy: 0.1996\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9042 - accuracy: 0.1979 - val_loss: 2.8987 - val_accuracy: 0.2018\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9021 - accuracy: 0.1971 - val_loss: 2.8974 - val_accuracy: 0.1992\n",
            "Test Accuracy: 19.917984306812286\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1750 - accuracy: 0.1594 - val_loss: 2.9889 - val_accuracy: 0.1867\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9910 - accuracy: 0.1824 - val_loss: 2.9359 - val_accuracy: 0.1946\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9619 - accuracy: 0.1866 - val_loss: 2.9203 - val_accuracy: 0.1971\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9440 - accuracy: 0.1864 - val_loss: 2.9133 - val_accuracy: 0.1974\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9283 - accuracy: 0.1926 - val_loss: 2.9263 - val_accuracy: 0.1994\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9268 - accuracy: 0.1945 - val_loss: 2.8967 - val_accuracy: 0.1956\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9188 - accuracy: 0.1966 - val_loss: 2.8910 - val_accuracy: 0.1958\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9135 - accuracy: 0.1938 - val_loss: 2.8975 - val_accuracy: 0.1974\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9119 - accuracy: 0.1951 - val_loss: 2.9053 - val_accuracy: 0.2015\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9113 - accuracy: 0.1961 - val_loss: 2.8905 - val_accuracy: 0.1996\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9083 - accuracy: 0.1942 - val_loss: 2.8943 - val_accuracy: 0.1964\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9069 - accuracy: 0.1959 - val_loss: 2.8871 - val_accuracy: 0.2032\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9042 - accuracy: 0.1964 - val_loss: 2.8913 - val_accuracy: 0.1953\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9070 - accuracy: 0.1945 - val_loss: 2.8879 - val_accuracy: 0.2011\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9014 - accuracy: 0.1953 - val_loss: 2.8852 - val_accuracy: 0.2016\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9025 - accuracy: 0.1978 - val_loss: 2.8864 - val_accuracy: 0.2004\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8990 - accuracy: 0.1985 - val_loss: 2.8865 - val_accuracy: 0.1960\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8980 - accuracy: 0.1967 - val_loss: 2.8867 - val_accuracy: 0.2008\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8993 - accuracy: 0.1981 - val_loss: 2.8852 - val_accuracy: 0.1994\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8966 - accuracy: 0.1976 - val_loss: 2.8855 - val_accuracy: 0.2004\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8963 - accuracy: 0.1966 - val_loss: 2.8850 - val_accuracy: 0.2012\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8963 - accuracy: 0.1983 - val_loss: 2.8890 - val_accuracy: 0.1997\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8946 - accuracy: 0.1979 - val_loss: 2.8826 - val_accuracy: 0.2008\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8909 - accuracy: 0.1980 - val_loss: 2.8809 - val_accuracy: 0.2020\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8918 - accuracy: 0.1982 - val_loss: 2.8857 - val_accuracy: 0.1972\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8927 - accuracy: 0.1997 - val_loss: 2.8866 - val_accuracy: 0.1983\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8911 - accuracy: 0.1979 - val_loss: 2.8816 - val_accuracy: 0.2009\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8902 - accuracy: 0.1989 - val_loss: 2.8800 - val_accuracy: 0.2003\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8900 - accuracy: 0.1987 - val_loss: 2.8880 - val_accuracy: 0.1964\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8871 - accuracy: 0.1994 - val_loss: 2.8851 - val_accuracy: 0.2017\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8857 - accuracy: 0.1985 - val_loss: 2.8860 - val_accuracy: 0.2020\n",
            "Epoch 32/50\n",
            "819/820 [============================>.] - ETA: 0s - loss: 2.8861 - accuracy: 0.1993Restoring model weights from the end of the best epoch: 12.\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8860 - accuracy: 0.1993 - val_loss: 2.8799 - val_accuracy: 0.2014\n",
            "Epoch 32: early stopping\n",
            "Test Accuracy: 20.318296551704407\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.2407 - accuracy: 0.1278 - val_loss: 2.9997 - val_accuracy: 0.1756\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0163 - accuracy: 0.1691 - val_loss: 2.9557 - val_accuracy: 0.1859\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9848 - accuracy: 0.1779 - val_loss: 2.9431 - val_accuracy: 0.1923\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9716 - accuracy: 0.1807 - val_loss: 2.9457 - val_accuracy: 0.1948\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9659 - accuracy: 0.1815 - val_loss: 2.9336 - val_accuracy: 0.1985\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9594 - accuracy: 0.1833 - val_loss: 2.9253 - val_accuracy: 0.1961\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9517 - accuracy: 0.1851 - val_loss: 2.9224 - val_accuracy: 0.1921\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9488 - accuracy: 0.1863 - val_loss: 2.9134 - val_accuracy: 0.1966\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9388 - accuracy: 0.1875 - val_loss: 2.9124 - val_accuracy: 0.1960\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9356 - accuracy: 0.1883 - val_loss: 2.9090 - val_accuracy: 0.1978\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9324 - accuracy: 0.1915 - val_loss: 2.9087 - val_accuracy: 0.1971\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9282 - accuracy: 0.1913 - val_loss: 2.9037 - val_accuracy: 0.1996\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9299 - accuracy: 0.1890 - val_loss: 2.9034 - val_accuracy: 0.1955\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9283 - accuracy: 0.1912 - val_loss: 2.9073 - val_accuracy: 0.2010\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9275 - accuracy: 0.1919 - val_loss: 2.9038 - val_accuracy: 0.1979\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9247 - accuracy: 0.1901 - val_loss: 2.9026 - val_accuracy: 0.1998\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9235 - accuracy: 0.1916 - val_loss: 2.9030 - val_accuracy: 0.1972\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9234 - accuracy: 0.1907 - val_loss: 2.9059 - val_accuracy: 0.1999\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9212 - accuracy: 0.1905 - val_loss: 2.9022 - val_accuracy: 0.1976\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9216 - accuracy: 0.1923 - val_loss: 2.9136 - val_accuracy: 0.1952\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9214 - accuracy: 0.1913 - val_loss: 2.9030 - val_accuracy: 0.1987\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9182 - accuracy: 0.1915 - val_loss: 2.9041 - val_accuracy: 0.1989\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9191 - accuracy: 0.1926 - val_loss: 2.9028 - val_accuracy: 0.1987\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9197 - accuracy: 0.1915 - val_loss: 2.9044 - val_accuracy: 0.2008\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9174 - accuracy: 0.1931 - val_loss: 2.8995 - val_accuracy: 0.1998\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9183 - accuracy: 0.1936 - val_loss: 2.9076 - val_accuracy: 0.1949\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9146 - accuracy: 0.1941 - val_loss: 2.8999 - val_accuracy: 0.2015\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9189 - accuracy: 0.1929 - val_loss: 2.9046 - val_accuracy: 0.2003\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9146 - accuracy: 0.1942 - val_loss: 2.9005 - val_accuracy: 0.1988\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9138 - accuracy: 0.1932 - val_loss: 2.9005 - val_accuracy: 0.1974\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9146 - accuracy: 0.1935 - val_loss: 2.9032 - val_accuracy: 0.1988\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9143 - accuracy: 0.1948 - val_loss: 2.9036 - val_accuracy: 0.1994\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9142 - accuracy: 0.1937 - val_loss: 2.8984 - val_accuracy: 0.2019\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9130 - accuracy: 0.1947 - val_loss: 2.9046 - val_accuracy: 0.2004\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9132 - accuracy: 0.1933 - val_loss: 2.9006 - val_accuracy: 0.1991\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9127 - accuracy: 0.1944 - val_loss: 2.9029 - val_accuracy: 0.2003\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9123 - accuracy: 0.1942 - val_loss: 2.8991 - val_accuracy: 0.2006\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9125 - accuracy: 0.1941 - val_loss: 2.8982 - val_accuracy: 0.2016\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9118 - accuracy: 0.1928 - val_loss: 2.9005 - val_accuracy: 0.1998\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9128 - accuracy: 0.1934 - val_loss: 2.8988 - val_accuracy: 0.2016\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9109 - accuracy: 0.1943 - val_loss: 2.9086 - val_accuracy: 0.1974\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9107 - accuracy: 0.1928 - val_loss: 2.8987 - val_accuracy: 0.2022\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9105 - accuracy: 0.1916 - val_loss: 2.9092 - val_accuracy: 0.1979\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9094 - accuracy: 0.1925 - val_loss: 2.8982 - val_accuracy: 0.1985\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9112 - accuracy: 0.1944 - val_loss: 2.8976 - val_accuracy: 0.2022\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9096 - accuracy: 0.1943 - val_loss: 2.8985 - val_accuracy: 0.1963\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9103 - accuracy: 0.1936 - val_loss: 2.8994 - val_accuracy: 0.2020\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9089 - accuracy: 0.1942 - val_loss: 2.8977 - val_accuracy: 0.2016\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9097 - accuracy: 0.1949 - val_loss: 2.8978 - val_accuracy: 0.2016\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9104 - accuracy: 0.1943 - val_loss: 2.8986 - val_accuracy: 0.2021\n",
            "Test Accuracy: 20.21089643239975\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1325 - accuracy: 0.1634 - val_loss: 2.9449 - val_accuracy: 0.1864\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9756 - accuracy: 0.1844 - val_loss: 2.9268 - val_accuracy: 0.1953\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9495 - accuracy: 0.1901 - val_loss: 2.9081 - val_accuracy: 0.1996\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9361 - accuracy: 0.1903 - val_loss: 2.9020 - val_accuracy: 0.1998\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9272 - accuracy: 0.1916 - val_loss: 2.9010 - val_accuracy: 0.1960\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9178 - accuracy: 0.1949 - val_loss: 2.9000 - val_accuracy: 0.1977\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9149 - accuracy: 0.1941 - val_loss: 2.9166 - val_accuracy: 0.1959\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9124 - accuracy: 0.1952 - val_loss: 2.8916 - val_accuracy: 0.1993\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9087 - accuracy: 0.1975 - val_loss: 2.8895 - val_accuracy: 0.1977\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9082 - accuracy: 0.1970 - val_loss: 2.8899 - val_accuracy: 0.2004\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9061 - accuracy: 0.1974 - val_loss: 2.8834 - val_accuracy: 0.2011\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9032 - accuracy: 0.1984 - val_loss: 2.8842 - val_accuracy: 0.2003\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9040 - accuracy: 0.1970 - val_loss: 2.8847 - val_accuracy: 0.1982\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.9021 - accuracy: 0.1984 - val_loss: 2.8893 - val_accuracy: 0.1968\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9011 - accuracy: 0.1968 - val_loss: 2.8852 - val_accuracy: 0.2026\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8976 - accuracy: 0.1982 - val_loss: 2.8826 - val_accuracy: 0.1992\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8994 - accuracy: 0.1974 - val_loss: 2.8817 - val_accuracy: 0.1995\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8961 - accuracy: 0.1981 - val_loss: 2.8848 - val_accuracy: 0.2019\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8961 - accuracy: 0.1976 - val_loss: 2.8814 - val_accuracy: 0.2009\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8941 - accuracy: 0.1983 - val_loss: 2.8841 - val_accuracy: 0.1989\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8939 - accuracy: 0.1980 - val_loss: 2.8801 - val_accuracy: 0.2019\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8920 - accuracy: 0.1982 - val_loss: 2.8800 - val_accuracy: 0.2009\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8916 - accuracy: 0.1989 - val_loss: 2.8836 - val_accuracy: 0.1996\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8920 - accuracy: 0.1999 - val_loss: 2.8788 - val_accuracy: 0.1974\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8910 - accuracy: 0.1996 - val_loss: 2.8837 - val_accuracy: 0.2027\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8882 - accuracy: 0.2009 - val_loss: 2.8845 - val_accuracy: 0.2006\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8883 - accuracy: 0.1999 - val_loss: 2.8790 - val_accuracy: 0.2012\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8865 - accuracy: 0.2003 - val_loss: 2.8879 - val_accuracy: 0.2009\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8900 - accuracy: 0.1996 - val_loss: 2.8824 - val_accuracy: 0.2027\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8878 - accuracy: 0.1992 - val_loss: 2.8924 - val_accuracy: 0.2019\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8869 - accuracy: 0.1991 - val_loss: 2.8878 - val_accuracy: 0.2014\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8866 - accuracy: 0.2002 - val_loss: 2.8830 - val_accuracy: 0.2013\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8868 - accuracy: 0.2005 - val_loss: 2.8871 - val_accuracy: 0.2029\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8852 - accuracy: 0.2004 - val_loss: 2.8809 - val_accuracy: 0.2013\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8854 - accuracy: 0.2014 - val_loss: 2.8830 - val_accuracy: 0.2005\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8856 - accuracy: 0.2015 - val_loss: 2.8833 - val_accuracy: 0.2000\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8829 - accuracy: 0.2011 - val_loss: 2.8860 - val_accuracy: 0.2038\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8839 - accuracy: 0.2024 - val_loss: 2.8833 - val_accuracy: 0.2028\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8835 - accuracy: 0.2030 - val_loss: 2.8855 - val_accuracy: 0.2027\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8811 - accuracy: 0.2019 - val_loss: 2.8827 - val_accuracy: 0.2032\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8823 - accuracy: 0.2024 - val_loss: 2.8811 - val_accuracy: 0.2012\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8831 - accuracy: 0.2026 - val_loss: 2.8826 - val_accuracy: 0.2011\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8836 - accuracy: 0.2019 - val_loss: 2.8862 - val_accuracy: 0.2020\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8803 - accuracy: 0.2025 - val_loss: 2.8870 - val_accuracy: 0.2015\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8786 - accuracy: 0.2025 - val_loss: 2.8954 - val_accuracy: 0.2007\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8834 - accuracy: 0.2008 - val_loss: 2.8858 - val_accuracy: 0.2013\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8808 - accuracy: 0.2012 - val_loss: 2.8934 - val_accuracy: 0.2027\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8787 - accuracy: 0.2028 - val_loss: 2.8851 - val_accuracy: 0.2034\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8804 - accuracy: 0.2020 - val_loss: 2.8917 - val_accuracy: 0.2027\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8810 - accuracy: 0.2015 - val_loss: 2.8855 - val_accuracy: 0.2014\n",
            "Test Accuracy: 20.142550766468048\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 15s 16ms/step - loss: 3.1284 - accuracy: 0.1646 - val_loss: 2.9711 - val_accuracy: 0.1914\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9723 - accuracy: 0.1886 - val_loss: 2.9289 - val_accuracy: 0.1975\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9474 - accuracy: 0.1947 - val_loss: 2.9202 - val_accuracy: 0.1990\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9330 - accuracy: 0.1935 - val_loss: 2.9072 - val_accuracy: 0.2012\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9295 - accuracy: 0.1937 - val_loss: 2.9004 - val_accuracy: 0.1995\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9221 - accuracy: 0.1953 - val_loss: 2.8966 - val_accuracy: 0.2031\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9167 - accuracy: 0.1956 - val_loss: 2.8977 - val_accuracy: 0.1962\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9139 - accuracy: 0.1963 - val_loss: 2.8945 - val_accuracy: 0.1997\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9115 - accuracy: 0.1976 - val_loss: 2.8945 - val_accuracy: 0.1974\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9094 - accuracy: 0.1947 - val_loss: 2.8948 - val_accuracy: 0.2006\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9087 - accuracy: 0.1984 - val_loss: 2.8896 - val_accuracy: 0.1983\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9070 - accuracy: 0.1969 - val_loss: 2.8903 - val_accuracy: 0.2004\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9036 - accuracy: 0.1981 - val_loss: 2.8938 - val_accuracy: 0.1968\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9046 - accuracy: 0.1966 - val_loss: 2.8898 - val_accuracy: 0.1991\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9006 - accuracy: 0.1982 - val_loss: 2.8905 - val_accuracy: 0.1995\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9044 - accuracy: 0.1975 - val_loss: 2.8868 - val_accuracy: 0.2026\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9003 - accuracy: 0.1974 - val_loss: 2.8900 - val_accuracy: 0.1976\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9015 - accuracy: 0.1970 - val_loss: 2.8847 - val_accuracy: 0.2016\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8969 - accuracy: 0.1988 - val_loss: 2.8828 - val_accuracy: 0.2008\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8985 - accuracy: 0.1995 - val_loss: 2.8904 - val_accuracy: 0.2001\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8958 - accuracy: 0.1988 - val_loss: 2.8838 - val_accuracy: 0.2027\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8967 - accuracy: 0.1994 - val_loss: 2.8843 - val_accuracy: 0.1997\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8932 - accuracy: 0.2004 - val_loss: 2.8890 - val_accuracy: 0.2000\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8966 - accuracy: 0.1992 - val_loss: 2.8858 - val_accuracy: 0.2033\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8935 - accuracy: 0.1994 - val_loss: 2.8880 - val_accuracy: 0.1997\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8943 - accuracy: 0.1984 - val_loss: 2.8886 - val_accuracy: 0.2021\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8919 - accuracy: 0.1981 - val_loss: 2.8894 - val_accuracy: 0.2011\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8927 - accuracy: 0.1998 - val_loss: 2.8827 - val_accuracy: 0.2004\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8921 - accuracy: 0.1967 - val_loss: 2.8811 - val_accuracy: 0.2005\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8908 - accuracy: 0.1997 - val_loss: 2.8823 - val_accuracy: 0.2021\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8896 - accuracy: 0.1967 - val_loss: 2.8818 - val_accuracy: 0.2011\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8915 - accuracy: 0.1996 - val_loss: 2.8876 - val_accuracy: 0.2002\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8880 - accuracy: 0.1983 - val_loss: 2.8856 - val_accuracy: 0.2003\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8893 - accuracy: 0.1977 - val_loss: 2.8883 - val_accuracy: 0.1993\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8884 - accuracy: 0.1994 - val_loss: 2.8862 - val_accuracy: 0.2006\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8872 - accuracy: 0.1986 - val_loss: 2.8857 - val_accuracy: 0.2008\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8876 - accuracy: 0.1997 - val_loss: 2.8811 - val_accuracy: 0.2048\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8879 - accuracy: 0.1980 - val_loss: 2.8854 - val_accuracy: 0.2037\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8872 - accuracy: 0.1993 - val_loss: 2.8850 - val_accuracy: 0.1999\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8869 - accuracy: 0.1991 - val_loss: 2.8858 - val_accuracy: 0.2003\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8860 - accuracy: 0.1993 - val_loss: 2.8867 - val_accuracy: 0.2041\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8858 - accuracy: 0.1992 - val_loss: 2.8843 - val_accuracy: 0.1997\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8832 - accuracy: 0.2011 - val_loss: 2.8836 - val_accuracy: 0.2004\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8867 - accuracy: 0.2008 - val_loss: 2.8915 - val_accuracy: 0.2026\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8873 - accuracy: 0.1986 - val_loss: 2.8836 - val_accuracy: 0.2018\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8848 - accuracy: 0.1988 - val_loss: 2.8896 - val_accuracy: 0.2006\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8843 - accuracy: 0.1999 - val_loss: 2.8934 - val_accuracy: 0.2011\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8853 - accuracy: 0.2000 - val_loss: 2.8855 - val_accuracy: 0.2011\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8841 - accuracy: 0.1986 - val_loss: 2.8883 - val_accuracy: 0.2010\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 2.8823 - accuracy: 0.2002 - val_loss: 2.8831 - val_accuracy: 0.2021\n",
            "Test Accuracy: 20.21089643239975\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.2083 - accuracy: 0.1356 - val_loss: 2.9946 - val_accuracy: 0.1586\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0357 - accuracy: 0.1500 - val_loss: 2.9830 - val_accuracy: 0.1604\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0154 - accuracy: 0.1620 - val_loss: 2.9628 - val_accuracy: 0.1821\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9955 - accuracy: 0.1706 - val_loss: 2.9572 - val_accuracy: 0.1877\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9789 - accuracy: 0.1803 - val_loss: 2.9406 - val_accuracy: 0.1941\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9774 - accuracy: 0.1856 - val_loss: 2.9467 - val_accuracy: 0.1917\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9692 - accuracy: 0.1877 - val_loss: 2.9322 - val_accuracy: 0.1957\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9641 - accuracy: 0.1874 - val_loss: 2.9326 - val_accuracy: 0.1945\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9607 - accuracy: 0.1887 - val_loss: 2.9311 - val_accuracy: 0.1941\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9565 - accuracy: 0.1893 - val_loss: 2.9327 - val_accuracy: 0.1981\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9538 - accuracy: 0.1888 - val_loss: 2.9196 - val_accuracy: 0.1975\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9463 - accuracy: 0.1900 - val_loss: 2.9169 - val_accuracy: 0.1994\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9406 - accuracy: 0.1913 - val_loss: 2.9183 - val_accuracy: 0.1985\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9369 - accuracy: 0.1913 - val_loss: 2.9064 - val_accuracy: 0.1969\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9323 - accuracy: 0.1920 - val_loss: 2.9105 - val_accuracy: 0.1956\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9275 - accuracy: 0.1913 - val_loss: 2.9070 - val_accuracy: 0.1955\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9268 - accuracy: 0.1906 - val_loss: 2.9018 - val_accuracy: 0.1963\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9217 - accuracy: 0.1912 - val_loss: 2.9025 - val_accuracy: 0.1943\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9215 - accuracy: 0.1906 - val_loss: 2.9063 - val_accuracy: 0.1964\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9204 - accuracy: 0.1921 - val_loss: 2.9020 - val_accuracy: 0.1993\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9169 - accuracy: 0.1931 - val_loss: 2.8965 - val_accuracy: 0.2011\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9143 - accuracy: 0.1941 - val_loss: 2.8969 - val_accuracy: 0.1985\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9153 - accuracy: 0.1932 - val_loss: 2.8948 - val_accuracy: 0.1964\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9103 - accuracy: 0.1943 - val_loss: 2.8960 - val_accuracy: 0.1968\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9124 - accuracy: 0.1936 - val_loss: 2.8939 - val_accuracy: 0.1976\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9130 - accuracy: 0.1943 - val_loss: 2.9003 - val_accuracy: 0.1968\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9112 - accuracy: 0.1940 - val_loss: 2.8955 - val_accuracy: 0.1997\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9086 - accuracy: 0.1939 - val_loss: 2.8915 - val_accuracy: 0.1991\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9101 - accuracy: 0.1950 - val_loss: 2.8954 - val_accuracy: 0.1984\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9101 - accuracy: 0.1935 - val_loss: 2.8982 - val_accuracy: 0.1988\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9103 - accuracy: 0.1937 - val_loss: 2.8939 - val_accuracy: 0.2004\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9091 - accuracy: 0.1952 - val_loss: 2.8988 - val_accuracy: 0.1989\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9080 - accuracy: 0.1952 - val_loss: 2.8940 - val_accuracy: 0.1996\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9085 - accuracy: 0.1951 - val_loss: 2.8971 - val_accuracy: 0.2004\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9053 - accuracy: 0.1955 - val_loss: 2.8976 - val_accuracy: 0.2004\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9068 - accuracy: 0.1955 - val_loss: 2.8949 - val_accuracy: 0.1999\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9033 - accuracy: 0.1968 - val_loss: 2.8928 - val_accuracy: 0.1970\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9029 - accuracy: 0.1980 - val_loss: 2.8898 - val_accuracy: 0.1993\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8991 - accuracy: 0.1971 - val_loss: 2.8923 - val_accuracy: 0.2017\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8998 - accuracy: 0.1969 - val_loss: 2.8934 - val_accuracy: 0.1988\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8982 - accuracy: 0.1983 - val_loss: 2.8891 - val_accuracy: 0.2008\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8976 - accuracy: 0.1981 - val_loss: 2.8923 - val_accuracy: 0.2018\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8968 - accuracy: 0.1984 - val_loss: 2.8930 - val_accuracy: 0.2023\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8979 - accuracy: 0.1986 - val_loss: 2.8926 - val_accuracy: 0.2013\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8966 - accuracy: 0.1996 - val_loss: 2.8897 - val_accuracy: 0.2018\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8955 - accuracy: 0.1999 - val_loss: 2.8899 - val_accuracy: 0.2025\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8959 - accuracy: 0.1976 - val_loss: 2.8928 - val_accuracy: 0.2017\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8939 - accuracy: 0.2001 - val_loss: 2.8890 - val_accuracy: 0.2024\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8937 - accuracy: 0.1992 - val_loss: 2.9004 - val_accuracy: 0.1985\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8929 - accuracy: 0.2008 - val_loss: 2.8971 - val_accuracy: 0.2040\n",
            "Test Accuracy: 20.396406948566437\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.1493 - accuracy: 0.1554 - val_loss: 2.9591 - val_accuracy: 0.1947\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9794 - accuracy: 0.1853 - val_loss: 2.9241 - val_accuracy: 0.1944\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9501 - accuracy: 0.1911 - val_loss: 2.9133 - val_accuracy: 0.1961\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9353 - accuracy: 0.1917 - val_loss: 2.9163 - val_accuracy: 0.1960\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9291 - accuracy: 0.1946 - val_loss: 2.9058 - val_accuracy: 0.2013\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9239 - accuracy: 0.1959 - val_loss: 2.8970 - val_accuracy: 0.1939\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9188 - accuracy: 0.1950 - val_loss: 2.9057 - val_accuracy: 0.1899\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9156 - accuracy: 0.1963 - val_loss: 2.9026 - val_accuracy: 0.1950\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9115 - accuracy: 0.1978 - val_loss: 2.8978 - val_accuracy: 0.1997\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9107 - accuracy: 0.1961 - val_loss: 2.8874 - val_accuracy: 0.1945\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9061 - accuracy: 0.1971 - val_loss: 2.8900 - val_accuracy: 0.1962\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9041 - accuracy: 0.1964 - val_loss: 2.8859 - val_accuracy: 0.1980\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8987 - accuracy: 0.1966 - val_loss: 2.8863 - val_accuracy: 0.2004\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9000 - accuracy: 0.1950 - val_loss: 2.8820 - val_accuracy: 0.1957\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8989 - accuracy: 0.1976 - val_loss: 2.8929 - val_accuracy: 0.2002\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8977 - accuracy: 0.1984 - val_loss: 2.8821 - val_accuracy: 0.1999\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8976 - accuracy: 0.2001 - val_loss: 2.8882 - val_accuracy: 0.1984\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8969 - accuracy: 0.1991 - val_loss: 2.8821 - val_accuracy: 0.1968\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8960 - accuracy: 0.1989 - val_loss: 2.8868 - val_accuracy: 0.1995\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8928 - accuracy: 0.1985 - val_loss: 2.8845 - val_accuracy: 0.1986\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8921 - accuracy: 0.1991 - val_loss: 2.8832 - val_accuracy: 0.2008\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8914 - accuracy: 0.1990 - val_loss: 2.8822 - val_accuracy: 0.2002\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8888 - accuracy: 0.1988 - val_loss: 2.8814 - val_accuracy: 0.2017\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8906 - accuracy: 0.1999 - val_loss: 2.8880 - val_accuracy: 0.1989\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8877 - accuracy: 0.1998 - val_loss: 2.8814 - val_accuracy: 0.2010\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8886 - accuracy: 0.1991 - val_loss: 2.8811 - val_accuracy: 0.2012\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8862 - accuracy: 0.1998 - val_loss: 2.8814 - val_accuracy: 0.2001\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8873 - accuracy: 0.1990 - val_loss: 2.8816 - val_accuracy: 0.2015\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8863 - accuracy: 0.1989 - val_loss: 2.8823 - val_accuracy: 0.1973\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8849 - accuracy: 0.1994 - val_loss: 2.8820 - val_accuracy: 0.2005\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8848 - accuracy: 0.2013 - val_loss: 2.8862 - val_accuracy: 0.2008\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8854 - accuracy: 0.1994 - val_loss: 2.8842 - val_accuracy: 0.2017\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8852 - accuracy: 0.2001 - val_loss: 2.8828 - val_accuracy: 0.1990\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8851 - accuracy: 0.2001 - val_loss: 2.8849 - val_accuracy: 0.2008\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8852 - accuracy: 0.2000 - val_loss: 2.8824 - val_accuracy: 0.1979\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8839 - accuracy: 0.2002 - val_loss: 2.8859 - val_accuracy: 0.2009\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8838 - accuracy: 0.2005 - val_loss: 2.8814 - val_accuracy: 0.2028\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8827 - accuracy: 0.1996 - val_loss: 2.8858 - val_accuracy: 0.2020\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8826 - accuracy: 0.1994 - val_loss: 2.8877 - val_accuracy: 0.2016\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8834 - accuracy: 0.2010 - val_loss: 2.8808 - val_accuracy: 0.2040\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8815 - accuracy: 0.1991 - val_loss: 2.8884 - val_accuracy: 0.2002\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8827 - accuracy: 0.2001 - val_loss: 2.8875 - val_accuracy: 0.2003\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8824 - accuracy: 0.1998 - val_loss: 2.8873 - val_accuracy: 0.2012\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8806 - accuracy: 0.1996 - val_loss: 2.8895 - val_accuracy: 0.2014\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8799 - accuracy: 0.2004 - val_loss: 2.8870 - val_accuracy: 0.2015\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8800 - accuracy: 0.1997 - val_loss: 2.8911 - val_accuracy: 0.2016\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8802 - accuracy: 0.2006 - val_loss: 2.8937 - val_accuracy: 0.2020\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8782 - accuracy: 0.2025 - val_loss: 2.8913 - val_accuracy: 0.2012\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8793 - accuracy: 0.2006 - val_loss: 2.8917 - val_accuracy: 0.2015\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8793 - accuracy: 0.2002 - val_loss: 2.8822 - val_accuracy: 0.2003\n",
            "Test Accuracy: 20.025385916233063\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 16ms/step - loss: 3.2616 - accuracy: 0.1291 - val_loss: 3.0258 - val_accuracy: 0.1745\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0556 - accuracy: 0.1647 - val_loss: 2.9846 - val_accuracy: 0.1904\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0354 - accuracy: 0.1694 - val_loss: 3.0177 - val_accuracy: 0.1932\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0232 - accuracy: 0.1717 - val_loss: 2.9835 - val_accuracy: 0.1884\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0165 - accuracy: 0.1708 - val_loss: 2.9672 - val_accuracy: 0.1959\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0011 - accuracy: 0.1709 - val_loss: 2.9519 - val_accuracy: 0.1828\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9805 - accuracy: 0.1729 - val_loss: 2.9435 - val_accuracy: 0.1894\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9724 - accuracy: 0.1772 - val_loss: 2.9361 - val_accuracy: 0.1929\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9663 - accuracy: 0.1802 - val_loss: 2.9307 - val_accuracy: 0.1888\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9568 - accuracy: 0.1827 - val_loss: 2.9366 - val_accuracy: 0.1874\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9566 - accuracy: 0.1833 - val_loss: 2.9234 - val_accuracy: 0.1913\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9535 - accuracy: 0.1839 - val_loss: 2.9218 - val_accuracy: 0.1895\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9490 - accuracy: 0.1847 - val_loss: 2.9271 - val_accuracy: 0.1934\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9494 - accuracy: 0.1848 - val_loss: 2.9244 - val_accuracy: 0.1896\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9514 - accuracy: 0.1853 - val_loss: 2.9230 - val_accuracy: 0.1988\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9479 - accuracy: 0.1852 - val_loss: 2.9238 - val_accuracy: 0.1933\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9459 - accuracy: 0.1847 - val_loss: 2.9244 - val_accuracy: 0.1991\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9463 - accuracy: 0.1870 - val_loss: 2.9351 - val_accuracy: 0.1973\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9448 - accuracy: 0.1843 - val_loss: 2.9280 - val_accuracy: 0.1968\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9477 - accuracy: 0.1845 - val_loss: 2.9241 - val_accuracy: 0.1909\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9442 - accuracy: 0.1854 - val_loss: 2.9217 - val_accuracy: 0.1976\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9432 - accuracy: 0.1850 - val_loss: 2.9235 - val_accuracy: 0.1970\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9410 - accuracy: 0.1858 - val_loss: 2.9239 - val_accuracy: 0.1967\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9420 - accuracy: 0.1876 - val_loss: 2.9220 - val_accuracy: 0.1969\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9412 - accuracy: 0.1864 - val_loss: 2.9188 - val_accuracy: 0.1991\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9401 - accuracy: 0.1864 - val_loss: 2.9225 - val_accuracy: 0.1968\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9390 - accuracy: 0.1870 - val_loss: 2.9242 - val_accuracy: 0.1963\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9391 - accuracy: 0.1885 - val_loss: 2.9202 - val_accuracy: 0.1970\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9390 - accuracy: 0.1883 - val_loss: 2.9246 - val_accuracy: 0.1991\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9398 - accuracy: 0.1879 - val_loss: 2.9181 - val_accuracy: 0.1993\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9397 - accuracy: 0.1874 - val_loss: 2.9192 - val_accuracy: 0.1994\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9367 - accuracy: 0.1883 - val_loss: 2.9180 - val_accuracy: 0.1913\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9378 - accuracy: 0.1871 - val_loss: 2.9166 - val_accuracy: 0.1993\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9374 - accuracy: 0.1874 - val_loss: 2.9209 - val_accuracy: 0.1921\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9399 - accuracy: 0.1867 - val_loss: 2.9328 - val_accuracy: 0.1948\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9387 - accuracy: 0.1869 - val_loss: 2.9198 - val_accuracy: 0.1921\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9366 - accuracy: 0.1870 - val_loss: 2.9191 - val_accuracy: 0.1934\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9389 - accuracy: 0.1881 - val_loss: 2.9186 - val_accuracy: 0.1995\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9342 - accuracy: 0.1909 - val_loss: 2.9181 - val_accuracy: 0.1990\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9295 - accuracy: 0.1919 - val_loss: 2.9104 - val_accuracy: 0.1976\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9263 - accuracy: 0.1912 - val_loss: 2.9081 - val_accuracy: 0.1985\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9218 - accuracy: 0.1918 - val_loss: 2.9051 - val_accuracy: 0.2004\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9212 - accuracy: 0.1935 - val_loss: 2.9035 - val_accuracy: 0.1991\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9203 - accuracy: 0.1928 - val_loss: 2.9018 - val_accuracy: 0.1992\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9193 - accuracy: 0.1932 - val_loss: 2.9018 - val_accuracy: 0.1998\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9185 - accuracy: 0.1919 - val_loss: 2.9021 - val_accuracy: 0.2003\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9174 - accuracy: 0.1919 - val_loss: 2.9018 - val_accuracy: 0.2040\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9138 - accuracy: 0.1933 - val_loss: 2.9053 - val_accuracy: 0.2022\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9150 - accuracy: 0.1917 - val_loss: 2.9010 - val_accuracy: 0.2020\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9161 - accuracy: 0.1928 - val_loss: 2.9039 - val_accuracy: 0.2008\n",
            "Test Accuracy: 20.083968341350555\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 16ms/step - loss: 3.2152 - accuracy: 0.1356 - val_loss: 3.0377 - val_accuracy: 0.1807\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0359 - accuracy: 0.1746 - val_loss: 2.9771 - val_accuracy: 0.1958\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0027 - accuracy: 0.1816 - val_loss: 2.9475 - val_accuracy: 0.1927\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9886 - accuracy: 0.1808 - val_loss: 2.9547 - val_accuracy: 0.1958\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9786 - accuracy: 0.1836 - val_loss: 2.9357 - val_accuracy: 0.1976\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9759 - accuracy: 0.1841 - val_loss: 2.9381 - val_accuracy: 0.1973\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9693 - accuracy: 0.1860 - val_loss: 2.9309 - val_accuracy: 0.1974\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9668 - accuracy: 0.1844 - val_loss: 2.9300 - val_accuracy: 0.1943\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9610 - accuracy: 0.1863 - val_loss: 2.9250 - val_accuracy: 0.1927\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9552 - accuracy: 0.1860 - val_loss: 2.9276 - val_accuracy: 0.1928\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9569 - accuracy: 0.1856 - val_loss: 2.9256 - val_accuracy: 0.1944\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9527 - accuracy: 0.1869 - val_loss: 2.9273 - val_accuracy: 0.1923\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9501 - accuracy: 0.1877 - val_loss: 2.9201 - val_accuracy: 0.1973\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9535 - accuracy: 0.1850 - val_loss: 2.9228 - val_accuracy: 0.1950\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9474 - accuracy: 0.1876 - val_loss: 2.9289 - val_accuracy: 0.1950\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9485 - accuracy: 0.1877 - val_loss: 2.9243 - val_accuracy: 0.1950\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9470 - accuracy: 0.1885 - val_loss: 2.9182 - val_accuracy: 0.1949\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9475 - accuracy: 0.1876 - val_loss: 2.9255 - val_accuracy: 0.1947\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9450 - accuracy: 0.1869 - val_loss: 2.9208 - val_accuracy: 0.1964\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9459 - accuracy: 0.1860 - val_loss: 2.9195 - val_accuracy: 0.1916\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9457 - accuracy: 0.1867 - val_loss: 2.9200 - val_accuracy: 0.1959\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9444 - accuracy: 0.1877 - val_loss: 2.9242 - val_accuracy: 0.1896\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9438 - accuracy: 0.1893 - val_loss: 2.9280 - val_accuracy: 0.1921\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9453 - accuracy: 0.1879 - val_loss: 2.9200 - val_accuracy: 0.1963\n",
            "Epoch 25/50\n",
            "819/820 [============================>.] - ETA: 0s - loss: 2.9430 - accuracy: 0.1879Restoring model weights from the end of the best epoch: 5.\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9429 - accuracy: 0.1879 - val_loss: 2.9224 - val_accuracy: 0.1971\n",
            "Epoch 25: early stopping\n",
            "Test Accuracy: 19.761765003204346\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.1591 - accuracy: 0.1596 - val_loss: 2.9703 - val_accuracy: 0.1920\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9783 - accuracy: 0.1857 - val_loss: 2.9232 - val_accuracy: 0.1954\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9508 - accuracy: 0.1908 - val_loss: 2.9102 - val_accuracy: 0.1975\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9368 - accuracy: 0.1930 - val_loss: 2.9138 - val_accuracy: 0.1971\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9286 - accuracy: 0.1925 - val_loss: 2.9007 - val_accuracy: 0.1970\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9203 - accuracy: 0.1950 - val_loss: 2.8960 - val_accuracy: 0.2022\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9171 - accuracy: 0.1954 - val_loss: 2.8966 - val_accuracy: 0.1985\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9155 - accuracy: 0.1954 - val_loss: 2.8947 - val_accuracy: 0.2015\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9108 - accuracy: 0.1969 - val_loss: 2.8985 - val_accuracy: 0.1969\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9093 - accuracy: 0.1953 - val_loss: 2.8888 - val_accuracy: 0.1974\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9073 - accuracy: 0.1955 - val_loss: 2.8859 - val_accuracy: 0.1990\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9054 - accuracy: 0.1956 - val_loss: 2.8833 - val_accuracy: 0.1973\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9035 - accuracy: 0.1967 - val_loss: 2.8829 - val_accuracy: 0.2012\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9016 - accuracy: 0.1949 - val_loss: 2.8801 - val_accuracy: 0.1968\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8997 - accuracy: 0.1968 - val_loss: 2.8849 - val_accuracy: 0.1995\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8969 - accuracy: 0.1963 - val_loss: 2.8809 - val_accuracy: 0.2017\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8953 - accuracy: 0.1967 - val_loss: 2.8850 - val_accuracy: 0.2002\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8935 - accuracy: 0.2004 - val_loss: 2.8787 - val_accuracy: 0.2010\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8922 - accuracy: 0.2006 - val_loss: 2.8782 - val_accuracy: 0.2006\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8907 - accuracy: 0.2000 - val_loss: 2.8798 - val_accuracy: 0.2020\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8881 - accuracy: 0.2008 - val_loss: 2.8805 - val_accuracy: 0.2024\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8861 - accuracy: 0.2010 - val_loss: 2.8772 - val_accuracy: 0.2022\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8858 - accuracy: 0.2013 - val_loss: 2.8794 - val_accuracy: 0.1996\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8846 - accuracy: 0.2010 - val_loss: 2.8774 - val_accuracy: 0.2006\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8840 - accuracy: 0.2012 - val_loss: 2.8814 - val_accuracy: 0.2026\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8843 - accuracy: 0.2023 - val_loss: 2.8805 - val_accuracy: 0.2030\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 14s 16ms/step - loss: 2.8831 - accuracy: 0.2007 - val_loss: 2.8808 - val_accuracy: 0.2017\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8819 - accuracy: 0.2020 - val_loss: 2.8822 - val_accuracy: 0.2026\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8809 - accuracy: 0.2044 - val_loss: 2.8815 - val_accuracy: 0.1998\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8785 - accuracy: 0.2012 - val_loss: 2.8801 - val_accuracy: 0.2052\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8795 - accuracy: 0.2014 - val_loss: 2.8803 - val_accuracy: 0.2013\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8783 - accuracy: 0.2013 - val_loss: 2.8785 - val_accuracy: 0.2037\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8797 - accuracy: 0.2006 - val_loss: 2.8779 - val_accuracy: 0.2032\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8779 - accuracy: 0.2017 - val_loss: 2.8804 - val_accuracy: 0.2002\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8779 - accuracy: 0.2019 - val_loss: 2.8821 - val_accuracy: 0.2030\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8785 - accuracy: 0.2022 - val_loss: 2.8813 - val_accuracy: 0.2038\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8766 - accuracy: 0.2031 - val_loss: 2.8787 - val_accuracy: 0.2003\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8746 - accuracy: 0.2028 - val_loss: 2.8822 - val_accuracy: 0.2006\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8752 - accuracy: 0.2027 - val_loss: 2.8809 - val_accuracy: 0.2030\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8749 - accuracy: 0.2031 - val_loss: 2.8851 - val_accuracy: 0.2039\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8730 - accuracy: 0.2026 - val_loss: 2.8837 - val_accuracy: 0.2037\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8732 - accuracy: 0.2008 - val_loss: 2.8837 - val_accuracy: 0.2036\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8753 - accuracy: 0.2025 - val_loss: 2.8829 - val_accuracy: 0.2045\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8723 - accuracy: 0.2019 - val_loss: 2.8819 - val_accuracy: 0.2005\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8731 - accuracy: 0.2030 - val_loss: 2.8883 - val_accuracy: 0.2036\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8738 - accuracy: 0.2033 - val_loss: 2.8826 - val_accuracy: 0.2019\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8733 - accuracy: 0.2033 - val_loss: 2.8882 - val_accuracy: 0.2036\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8714 - accuracy: 0.2022 - val_loss: 2.8858 - val_accuracy: 0.2016\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8716 - accuracy: 0.2024 - val_loss: 2.8827 - val_accuracy: 0.2045\n",
            "Epoch 50/50\n",
            "817/820 [============================>.] - ETA: 0s - loss: 2.8720 - accuracy: 0.2027Restoring model weights from the end of the best epoch: 30.\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.8719 - accuracy: 0.2027 - val_loss: 2.8915 - val_accuracy: 0.2019\n",
            "Epoch 50: early stopping\n",
            "Test Accuracy: 20.52333503961563\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.6765 - accuracy: 0.1280 - val_loss: 3.4818 - val_accuracy: 0.1304\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.3782 - accuracy: 0.1305 - val_loss: 3.3018 - val_accuracy: 0.1304\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.2619 - accuracy: 0.1305 - val_loss: 3.2325 - val_accuracy: 0.1304\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.2167 - accuracy: 0.1305 - val_loss: 3.2040 - val_accuracy: 0.1304\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1961 - accuracy: 0.1305 - val_loss: 3.1890 - val_accuracy: 0.1304\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 3.1842 - accuracy: 0.1305 - val_loss: 3.1797 - val_accuracy: 0.1304\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1766 - accuracy: 0.1305 - val_loss: 3.1735 - val_accuracy: 0.1304\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 3.1715 - accuracy: 0.1305 - val_loss: 3.1693 - val_accuracy: 0.1304\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1679 - accuracy: 0.1305 - val_loss: 3.1664 - val_accuracy: 0.1304\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1655 - accuracy: 0.1305 - val_loss: 3.1643 - val_accuracy: 0.1304\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1637 - accuracy: 0.1305 - val_loss: 3.1628 - val_accuracy: 0.1304\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1625 - accuracy: 0.1305 - val_loss: 3.1618 - val_accuracy: 0.1304\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1616 - accuracy: 0.1305 - val_loss: 3.1610 - val_accuracy: 0.1304\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1610 - accuracy: 0.1305 - val_loss: 3.1605 - val_accuracy: 0.1304\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1605 - accuracy: 0.1305 - val_loss: 3.1602 - val_accuracy: 0.1304\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1602 - accuracy: 0.1305 - val_loss: 3.1599 - val_accuracy: 0.1304\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1600 - accuracy: 0.1305 - val_loss: 3.1597 - val_accuracy: 0.1304\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1598 - accuracy: 0.1305 - val_loss: 3.1595 - val_accuracy: 0.1304\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1597 - accuracy: 0.1305 - val_loss: 3.1594 - val_accuracy: 0.1304\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.1596 - accuracy: 0.1305 - val_loss: 3.1594 - val_accuracy: 0.1304\n",
            "Epoch 21/50\n",
            "817/820 [============================>.] - ETA: 0s - loss: 3.1596 - accuracy: 0.1305Restoring model weights from the end of the best epoch: 1.\n",
            "820/820 [==============================] - 13s 15ms/step - loss: 3.1595 - accuracy: 0.1305 - val_loss: 3.1593 - val_accuracy: 0.1304\n",
            "Epoch 21: early stopping\n",
            "Test Accuracy: 13.0443274974823\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.2329 - accuracy: 0.1352 - val_loss: 2.9940 - val_accuracy: 0.1746\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0323 - accuracy: 0.1772 - val_loss: 2.9729 - val_accuracy: 0.1957\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0033 - accuracy: 0.1816 - val_loss: 2.9560 - val_accuracy: 0.1879\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9928 - accuracy: 0.1824 - val_loss: 2.9414 - val_accuracy: 0.1921\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9840 - accuracy: 0.1822 - val_loss: 2.9632 - val_accuracy: 0.1950\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9810 - accuracy: 0.1843 - val_loss: 2.9456 - val_accuracy: 0.1953\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9747 - accuracy: 0.1826 - val_loss: 2.9332 - val_accuracy: 0.1985\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9709 - accuracy: 0.1832 - val_loss: 2.9356 - val_accuracy: 0.1970\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9679 - accuracy: 0.1825 - val_loss: 2.9315 - val_accuracy: 0.1941\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9637 - accuracy: 0.1823 - val_loss: 2.9297 - val_accuracy: 0.1964\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9569 - accuracy: 0.1832 - val_loss: 2.9290 - val_accuracy: 0.1939\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9572 - accuracy: 0.1820 - val_loss: 2.9337 - val_accuracy: 0.1951\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9543 - accuracy: 0.1822 - val_loss: 2.9220 - val_accuracy: 0.1944\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9517 - accuracy: 0.1834 - val_loss: 2.9238 - val_accuracy: 0.1939\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9504 - accuracy: 0.1865 - val_loss: 2.9281 - val_accuracy: 0.1897\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9496 - accuracy: 0.1858 - val_loss: 2.9213 - val_accuracy: 0.1939\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9494 - accuracy: 0.1863 - val_loss: 2.9181 - val_accuracy: 0.1946\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9485 - accuracy: 0.1861 - val_loss: 2.9206 - val_accuracy: 0.1944\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9473 - accuracy: 0.1874 - val_loss: 2.9238 - val_accuracy: 0.1965\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9468 - accuracy: 0.1876 - val_loss: 2.9237 - val_accuracy: 0.1961\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9455 - accuracy: 0.1867 - val_loss: 2.9198 - val_accuracy: 0.1944\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9436 - accuracy: 0.1873 - val_loss: 2.9255 - val_accuracy: 0.1948\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9455 - accuracy: 0.1888 - val_loss: 2.9222 - val_accuracy: 0.1960\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9439 - accuracy: 0.1861 - val_loss: 2.9230 - val_accuracy: 0.1941\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9453 - accuracy: 0.1861 - val_loss: 2.9189 - val_accuracy: 0.1949\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9434 - accuracy: 0.1869 - val_loss: 2.9227 - val_accuracy: 0.1940\n",
            "Epoch 27/50\n",
            "817/820 [============================>.] - ETA: 0s - loss: 2.9435 - accuracy: 0.1867Restoring model weights from the end of the best epoch: 7.\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9440 - accuracy: 0.1865 - val_loss: 2.9188 - val_accuracy: 0.1962\n",
            "Epoch 27: early stopping\n",
            "Test Accuracy: 19.849638640880585\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.2531 - accuracy: 0.1311 - val_loss: 3.0484 - val_accuracy: 0.1521\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0590 - accuracy: 0.1611 - val_loss: 2.9909 - val_accuracy: 0.1558\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 3.0401 - accuracy: 0.1660 - val_loss: 2.9937 - val_accuracy: 0.1807\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0260 - accuracy: 0.1796 - val_loss: 2.9806 - val_accuracy: 0.1925\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0177 - accuracy: 0.1818 - val_loss: 2.9677 - val_accuracy: 0.1937\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0082 - accuracy: 0.1821 - val_loss: 2.9664 - val_accuracy: 0.1979\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 3.0027 - accuracy: 0.1842 - val_loss: 2.9600 - val_accuracy: 0.1943\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9963 - accuracy: 0.1834 - val_loss: 2.9627 - val_accuracy: 0.1939\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9830 - accuracy: 0.1850 - val_loss: 2.9373 - val_accuracy: 0.1913\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9632 - accuracy: 0.1883 - val_loss: 2.9404 - val_accuracy: 0.1961\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9551 - accuracy: 0.1895 - val_loss: 2.9319 - val_accuracy: 0.1941\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9510 - accuracy: 0.1891 - val_loss: 2.9225 - val_accuracy: 0.1943\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9492 - accuracy: 0.1884 - val_loss: 2.9204 - val_accuracy: 0.1977\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9478 - accuracy: 0.1897 - val_loss: 2.9230 - val_accuracy: 0.1937\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9461 - accuracy: 0.1896 - val_loss: 2.9185 - val_accuracy: 0.1980\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9452 - accuracy: 0.1895 - val_loss: 2.9208 - val_accuracy: 0.1981\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9451 - accuracy: 0.1901 - val_loss: 2.9191 - val_accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9437 - accuracy: 0.1907 - val_loss: 2.9176 - val_accuracy: 0.1978\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9450 - accuracy: 0.1905 - val_loss: 2.9210 - val_accuracy: 0.1978\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9373 - accuracy: 0.1918 - val_loss: 2.9166 - val_accuracy: 0.1995\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9376 - accuracy: 0.1921 - val_loss: 2.9156 - val_accuracy: 0.1982\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9335 - accuracy: 0.1928 - val_loss: 2.9118 - val_accuracy: 0.1960\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9338 - accuracy: 0.1916 - val_loss: 2.9135 - val_accuracy: 0.1967\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9299 - accuracy: 0.1930 - val_loss: 2.9140 - val_accuracy: 0.1989\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9326 - accuracy: 0.1911 - val_loss: 2.9197 - val_accuracy: 0.1986\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9303 - accuracy: 0.1939 - val_loss: 2.9092 - val_accuracy: 0.1986\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9291 - accuracy: 0.1924 - val_loss: 2.9094 - val_accuracy: 0.1983\n",
            "Epoch 28/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9268 - accuracy: 0.1929 - val_loss: 2.9069 - val_accuracy: 0.2021\n",
            "Epoch 29/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9240 - accuracy: 0.1943 - val_loss: 2.9096 - val_accuracy: 0.1998\n",
            "Epoch 30/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9253 - accuracy: 0.1938 - val_loss: 2.9101 - val_accuracy: 0.1957\n",
            "Epoch 31/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9236 - accuracy: 0.1936 - val_loss: 2.9049 - val_accuracy: 0.1992\n",
            "Epoch 32/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9244 - accuracy: 0.1937 - val_loss: 2.9076 - val_accuracy: 0.1997\n",
            "Epoch 33/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9239 - accuracy: 0.1930 - val_loss: 2.9122 - val_accuracy: 0.2004\n",
            "Epoch 34/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9211 - accuracy: 0.1946 - val_loss: 2.9109 - val_accuracy: 0.2028\n",
            "Epoch 35/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9227 - accuracy: 0.1938 - val_loss: 2.9143 - val_accuracy: 0.1969\n",
            "Epoch 36/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9222 - accuracy: 0.1950 - val_loss: 2.9057 - val_accuracy: 0.1963\n",
            "Epoch 37/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9209 - accuracy: 0.1964 - val_loss: 2.9093 - val_accuracy: 0.1989\n",
            "Epoch 38/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9179 - accuracy: 0.1937 - val_loss: 2.9112 - val_accuracy: 0.2004\n",
            "Epoch 39/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9194 - accuracy: 0.1950 - val_loss: 2.9061 - val_accuracy: 0.2010\n",
            "Epoch 40/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9151 - accuracy: 0.1980 - val_loss: 2.9012 - val_accuracy: 0.2009\n",
            "Epoch 41/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9134 - accuracy: 0.1973 - val_loss: 2.9019 - val_accuracy: 0.1994\n",
            "Epoch 42/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9130 - accuracy: 0.1966 - val_loss: 2.8999 - val_accuracy: 0.2017\n",
            "Epoch 43/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9109 - accuracy: 0.1961 - val_loss: 2.8957 - val_accuracy: 0.2009\n",
            "Epoch 44/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9118 - accuracy: 0.1957 - val_loss: 2.8985 - val_accuracy: 0.2017\n",
            "Epoch 45/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9114 - accuracy: 0.1969 - val_loss: 2.9039 - val_accuracy: 0.1983\n",
            "Epoch 46/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9096 - accuracy: 0.1973 - val_loss: 2.8947 - val_accuracy: 0.2011\n",
            "Epoch 47/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9068 - accuracy: 0.1973 - val_loss: 2.8939 - val_accuracy: 0.2015\n",
            "Epoch 48/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9056 - accuracy: 0.1974 - val_loss: 2.8956 - val_accuracy: 0.2000\n",
            "Epoch 49/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9041 - accuracy: 0.1979 - val_loss: 2.8963 - val_accuracy: 0.2006\n",
            "Epoch 50/50\n",
            "820/820 [==============================] - 14s 16ms/step - loss: 2.9042 - accuracy: 0.1978 - val_loss: 2.8945 - val_accuracy: 0.2022\n",
            "Test Accuracy: 20.22065967321396\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.1724 - accuracy: 0.1559 - val_loss: 2.9603 - val_accuracy: 0.1932\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9903 - accuracy: 0.1829 - val_loss: 2.9305 - val_accuracy: 0.1944\n",
            "Epoch 3/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9639 - accuracy: 0.1861 - val_loss: 2.9229 - val_accuracy: 0.1918\n",
            "Epoch 4/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9534 - accuracy: 0.1865 - val_loss: 2.9240 - val_accuracy: 0.1970\n",
            "Epoch 5/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9438 - accuracy: 0.1881 - val_loss: 2.9084 - val_accuracy: 0.1934\n",
            "Epoch 6/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9416 - accuracy: 0.1889 - val_loss: 2.9107 - val_accuracy: 0.1940\n",
            "Epoch 7/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9339 - accuracy: 0.1928 - val_loss: 2.9126 - val_accuracy: 0.1973\n",
            "Epoch 8/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9332 - accuracy: 0.1907 - val_loss: 2.9031 - val_accuracy: 0.2020\n",
            "Epoch 9/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9286 - accuracy: 0.1939 - val_loss: 2.9127 - val_accuracy: 0.1988\n",
            "Epoch 10/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9283 - accuracy: 0.1917 - val_loss: 2.9039 - val_accuracy: 0.1979\n",
            "Epoch 11/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9260 - accuracy: 0.1914 - val_loss: 2.9033 - val_accuracy: 0.1963\n",
            "Epoch 12/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9226 - accuracy: 0.1936 - val_loss: 2.9059 - val_accuracy: 0.1983\n",
            "Epoch 13/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9224 - accuracy: 0.1931 - val_loss: 2.9042 - val_accuracy: 0.1926\n",
            "Epoch 14/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9200 - accuracy: 0.1920 - val_loss: 2.8992 - val_accuracy: 0.1960\n",
            "Epoch 15/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9188 - accuracy: 0.1913 - val_loss: 2.8976 - val_accuracy: 0.1977\n",
            "Epoch 16/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9184 - accuracy: 0.1928 - val_loss: 2.8973 - val_accuracy: 0.1990\n",
            "Epoch 17/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9178 - accuracy: 0.1943 - val_loss: 2.8992 - val_accuracy: 0.2001\n",
            "Epoch 18/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9171 - accuracy: 0.1955 - val_loss: 2.9086 - val_accuracy: 0.1987\n",
            "Epoch 19/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9156 - accuracy: 0.1957 - val_loss: 2.8992 - val_accuracy: 0.1988\n",
            "Epoch 20/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9139 - accuracy: 0.1962 - val_loss: 2.8992 - val_accuracy: 0.1978\n",
            "Epoch 21/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9127 - accuracy: 0.1970 - val_loss: 2.9013 - val_accuracy: 0.1995\n",
            "Epoch 22/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9113 - accuracy: 0.1966 - val_loss: 2.9003 - val_accuracy: 0.1982\n",
            "Epoch 23/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9086 - accuracy: 0.1961 - val_loss: 2.8965 - val_accuracy: 0.1987\n",
            "Epoch 24/50\n",
            "820/820 [==============================] - 14s 17ms/step - loss: 2.9063 - accuracy: 0.1972 - val_loss: 2.8945 - val_accuracy: 0.2017\n",
            "Epoch 25/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9054 - accuracy: 0.1979 - val_loss: 2.8946 - val_accuracy: 0.2007\n",
            "Epoch 26/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9045 - accuracy: 0.1966 - val_loss: 2.9035 - val_accuracy: 0.1986\n",
            "Epoch 27/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9049 - accuracy: 0.1987 - val_loss: 2.8962 - val_accuracy: 0.1989\n",
            "Epoch 28/50\n",
            "819/820 [============================>.] - ETA: 0s - loss: 2.9024 - accuracy: 0.1967Restoring model weights from the end of the best epoch: 8.\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9022 - accuracy: 0.1967 - val_loss: 2.8955 - val_accuracy: 0.1982\n",
            "Epoch 28: early stopping\n",
            "Test Accuracy: 20.20113319158554\n",
            "The model suffered from local minimum. Retrain the model!\n",
            "Epoch 1/50\n",
            "820/820 [==============================] - 16s 17ms/step - loss: 3.1292 - accuracy: 0.1678 - val_loss: 2.9707 - val_accuracy: 0.1933\n",
            "Epoch 2/50\n",
            "820/820 [==============================] - 13s 16ms/step - loss: 2.9717 - accuracy: 0.1870 - val_loss: 2.9253 - val_accuracy: 0.1971\n",
            "Epoch 3/50\n",
            "470/820 [================>.............] - ETA: 5s - loss: 2.9500 - accuracy: 0.1878"
          ]
        }
      ],
      "source": [
        "# Parameter Initialization\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "activations = ['relu']\n",
        "filters = 100\n",
        "#kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
        "kernel_sizes = [3]\n",
        "emb_mean = emb_mean\n",
        "emb_std = emb_std\n",
        "\n",
        "columns = ['Activation', 'Filters', 'Acc']\n",
        "record2 = pd.DataFrame(columns = columns)\n",
        "\n",
        "train_y = y_train\n",
        "test_y = y_test\n",
        "\n",
        "exp = 0\n",
        "\n",
        "for activation in activations:\n",
        "\n",
        "    for kernel_size in kernel_sizes:\n",
        "        \n",
        "        exp+=1\n",
        "        print('-------------------------------------------')\n",
        "        print('Training {}: {} activation, {} kernel size.'.format(exp, activation, kernel_size))\n",
        "        print('-------------------------------------------')\n",
        "        \n",
        "        # encode data using\n",
        "        # Cleaning and Tokenization\n",
        "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "        tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "        # Turn the text into sequence\n",
        "        training_sequences = tokenizer.texts_to_sequences(X_train.comment_list_new)\n",
        "        test_sequences = tokenizer.texts_to_sequences(X_test.comment_list_new)\n",
        "\n",
        "        max_len = max_length(training_sequences)\n",
        "\n",
        "        # Pad the sequence to have the same size\n",
        "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "        word_index = tokenizer.word_index\n",
        "        vocab_size = len(word_index)+1\n",
        "\n",
        "        emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
        "\n",
        "        # Define the input shape\n",
        "        model = define_model_2(kernel_size, activation, input_dim=vocab_size, \n",
        "                             max_length=max_len, emb_matrix=emb_matrix)\n",
        "\n",
        "        # Train the model and initialize test accuracy with 0\n",
        "        acc = 0\n",
        "        while(acc<0.6):\n",
        "\n",
        "            model.fit(Xtrain, train_y, batch_size=50, epochs=50, verbose=1, \n",
        "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
        "\n",
        "            # evaluate the model\n",
        "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
        "            print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "            if (acc<0.6):\n",
        "                print('The model suffered from local minimum. Retrain the model!')\n",
        "                model = define_model_2(kernel_size, activation, input_dim=vocab_size, \n",
        "                                       max_length=max_len, emb_matrix=emb_matrix)\n",
        "            else:\n",
        "                print('Done!')\n",
        "\n",
        "        parameters = [activation, kernel_size]\n",
        "        entries = parameters + [acc]\n",
        "\n",
        "        temp = pd.DataFrame([entries], columns=columns)\n",
        "        record2 = record2.append(temp, ignore_index=True)\n",
        "        print()\n",
        "        print(record2)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUJU15plpWCk"
      },
      "source": [
        "# Random Forest Same as above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL8jqd-MEMYO"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "mode = 'count'\n",
        "filename = 'RF'\n",
        "\n",
        "def create_tokenizer(sentences):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "\n",
        "# Separate the sentences and the labels for training and testing\n",
        "train_x = list(X_train.Description)\n",
        "train_y = y_train\n",
        "print('train_x size: ', len(train_x))\n",
        "print('train_y size: ', len(train_y))\n",
        "\n",
        "test_x = list(X_test.Description)\n",
        "test_y = y_test\n",
        "print('test_x size: ', len(test_x))\n",
        "print('test_y size: ', len(test_y))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# Define the tokenizer\n",
        "tokenizer = create_tokenizer(train_x)\n",
        "    \n",
        "# encode data using freq mode\n",
        "Xtrain = tokenizer.texts_to_matrix(train_x, mode=mode)\n",
        "Xtest = tokenizer.texts_to_matrix(test_x, mode=mode)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(warm_start=True, max_features='log2',\n",
        "            random_state=127,\n",
        "            n_estimators=200,\n",
        "            n_jobs=-1)\n",
        "clf.fit(Xtrain, y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = clf.predict(Xtest)\n",
        "print (clf.score(Xtest, test_y, sample_weight=None))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "C_report=classification_report(test_y,y_pred)\n",
        "text_file = open(prefix+mode+filename, \"w\")\n",
        "n = text_file.write(C_report)\n",
        "text_file.close()\n",
        "\n",
        "\n",
        "#Pandas format of the report\n",
        "report_to_df(C_report, mode+filename)\n",
        "#Save C_report \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUFUynzcVAKk"
      },
      "outputs": [],
      "source": [
        "report_to_df(C_report, mode+filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32x5qAREkC4H"
      },
      "source": [
        "# Baseline \n",
        "Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgH0qn4e1inJ",
        "outputId": "de54fa07-6988-46bb-9dbf-ea6db391e6a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_x size:  40968\n",
            "train_y size:  40968\n",
            "test_x size:  10242\n",
            "test_y size:  10242\n",
            "0.850224565514548\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.61      0.71       186\n",
            "           1       0.97      0.67      0.79        54\n",
            "           3       0.88      0.74      0.80       141\n",
            "           4       0.81      0.89      0.85       532\n",
            "           8       0.69      0.79      0.74       254\n",
            "           9       0.83      0.85      0.84       432\n",
            "          10       0.82      0.89      0.85       442\n",
            "          11       0.91      0.86      0.89        99\n",
            "          12       0.96      0.76      0.85        94\n",
            "          13       0.82      0.93      0.87       391\n",
            "          15       0.79      0.85      0.82       256\n",
            "          17       0.94      0.73      0.82        63\n",
            "          18       0.82      0.91      0.86       249\n",
            "          19       0.89      0.65      0.75       131\n",
            "          22       0.96      0.93      0.95      1336\n",
            "          23       0.79      0.90      0.84       287\n",
            "          24       0.85      0.87      0.86       358\n",
            "          25       0.84      0.94      0.89       150\n",
            "          26       0.89      0.95      0.92        66\n",
            "          27       0.98      0.81      0.88        62\n",
            "          28       0.94      0.96      0.95       283\n",
            "          29       0.85      0.86      0.86       418\n",
            "          30       0.86      0.71      0.77        92\n",
            "          31       0.91      0.88      0.89      1041\n",
            "          32       0.82      0.91      0.86       594\n",
            "          33       0.92      0.85      0.89       141\n",
            "          34       0.92      0.96      0.94       291\n",
            "          35       0.91      0.89      0.90       459\n",
            "          36       0.77      0.73      0.75       404\n",
            "          38       0.90      0.39      0.54        90\n",
            "          40       0.69      0.76      0.72       686\n",
            "          43       0.97      0.49      0.65        67\n",
            "          50       0.75      0.10      0.17        93\n",
            "\n",
            "    accuracy                           0.85     10242\n",
            "   macro avg       0.86      0.79      0.81     10242\n",
            "weighted avg       0.85      0.85      0.85     10242\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mode = 'count'\n",
        "filename = 'NB'\n",
        "\n",
        "def create_tokenizer(sentences):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "\n",
        "# Separate the sentences and the labels for training and testing\n",
        "train_x = list(X_train.Description)\n",
        "train_y = y_train\n",
        "print('train_x size: ', len(train_x))\n",
        "print('train_y size: ', len(train_y))\n",
        "\n",
        "test_x = list(X_test.Description)\n",
        "test_y = y_test\n",
        "print('test_x size: ', len(test_x))\n",
        "print('test_y size: ', len(test_y))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "# Define the tokenizer\n",
        "tokenizer = create_tokenizer(train_x)\n",
        "    \n",
        "# encode data using freq mode\n",
        "Xtrain = tokenizer.texts_to_matrix(train_x, mode=mode)\n",
        "Xtest = tokenizer.texts_to_matrix(test_x, mode=mode)\n",
        "\n",
        "\n",
        "\n",
        "clfNB = naive_bayes.MultinomialNB()\n",
        "clfNB.fit(Xtrain, train_y)\n",
        "## test\n",
        "predicted = clfNB.predict(Xtest)\n",
        "predicted_prob = clfNB.predict_proba(Xtest)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = clfNB.predict(Xtest)\n",
        "print (clfNB.score(Xtest, test_y, sample_weight=None))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "C_report=classification_report(test_y,y_pred)\n",
        "text_file = open(prefix+mode+filename, \"w\")\n",
        "n = text_file.write(C_report)\n",
        "text_file.close()\n",
        "\n",
        "\n",
        "#Pandas format of the report\n",
        "report_to_df(C_report, mode+filename)\n",
        "#Save C_report \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl0nV3TLpn_e"
      },
      "source": [
        "# Extra: Create Report manually (if you like)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSI3CZsM6WCw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from  sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "y_true = np.array([0]*400 + [1]*600)\n",
        "y_pred = np.random.randint(2, size=1000)\n",
        "\n",
        "def pandas_classification_report(y_true, y_pred):\n",
        "    metrics_summary = precision_recall_fscore_support(\n",
        "            y_true=y_true, \n",
        "            y_pred=y_pred)\n",
        "    \n",
        "    avg = list(precision_recall_fscore_support(\n",
        "            y_true=y_true, \n",
        "            y_pred=y_pred,\n",
        "            average='weighted'))\n",
        "\n",
        "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
        "    class_report_df = pd.DataFrame(\n",
        "        list(metrics_summary),\n",
        "        index=metrics_sum_index)\n",
        "    \n",
        "    support = class_report_df.loc['support']\n",
        "    total = support.sum() \n",
        "    avg[-1] = total\n",
        "    \n",
        "    class_report_df['avg / total'] = avg\n",
        "\n",
        "    return class_report_df.T\n",
        "\n",
        "\n",
        "    header = ['Class Name']+[x for x in report[0] if x!='']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK8226OK6bf1",
        "outputId": "4f806ec0-06f2-4379-9e87-cfa929942ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score  support\n",
            "0             0.927273  0.822581  0.871795    186.0\n",
            "1             0.972973  0.666667  0.791209     54.0\n",
            "2             0.967742  0.851064  0.905660    141.0\n",
            "3             0.926966  0.930451  0.928705    532.0\n",
            "4             0.867769  0.826772  0.846774    254.0\n",
            "5             0.967213  0.956019  0.961583    432.0\n",
            "6             0.959459  0.963801  0.961625    442.0\n",
            "7             0.921569  0.949495  0.935323     99.0\n",
            "8             0.966667  0.925532  0.945652     94.0\n",
            "9             0.880668  0.943734  0.911111    391.0\n",
            "10            0.915058  0.925781  0.920388    256.0\n",
            "11            0.921875  0.936508  0.929134     63.0\n",
            "12            0.901575  0.919679  0.910537    249.0\n",
            "13            0.880342  0.786260  0.830645    131.0\n",
            "14            0.983558  0.985030  0.984293   1336.0\n",
            "15            0.942373  0.968641  0.955326    287.0\n",
            "16            0.912429  0.902235  0.907303    358.0\n",
            "17            0.951389  0.913333  0.931973    150.0\n",
            "18            0.923077  0.909091  0.916031     66.0\n",
            "19            0.953125  0.983871  0.968254     62.0\n",
            "20            0.955932  0.996466  0.975779    283.0\n",
            "21            0.922518  0.911483  0.916968    418.0\n",
            "22            0.860215  0.869565  0.864865     92.0\n",
            "23            0.951196  0.954851  0.953020   1041.0\n",
            "24            0.958194  0.964646  0.961409    594.0\n",
            "25            0.923664  0.858156  0.889706    141.0\n",
            "26            0.956081  0.972509  0.964225    291.0\n",
            "27            0.907527  0.919390  0.913420    459.0\n",
            "28            0.893506  0.851485  0.871990    404.0\n",
            "29            0.846154  0.733333  0.785714     90.0\n",
            "30            0.732429  0.865889  0.793587    686.0\n",
            "31            0.884615  0.686567  0.773109     67.0\n",
            "32            0.785714  0.354839  0.488889     93.0\n",
            "avg / total   0.921790  0.920230  0.919355  10242.0\n"
          ]
        }
      ],
      "source": [
        "df_class_report = pandas_classification_report(y_true=y_test, y_pred=y_pred)\n",
        "print(df_class_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohOZ-UXd6-Pt",
        "outputId": "80f3646d-d7b6-40c6-950c-c3cdf14fbe2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 16:19:50--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-04-21 16:19:50--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-21 16:19:50--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.16MB/s    in 2m 40s  \n",
            "\n",
            "2022-04-21 16:22:30 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "7ycNhUPW7t_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "3vr0do9N8SP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = dict()\n",
        "\n",
        "# load the whole embedding into memory\n",
        "f = open('glove.6B.300d.txt', encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_vectors[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(word_vectors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saSrg10s8KXo",
        "outputId": "faa5c1aa-89c1-43ae-9299-209231533274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "id": "w81IdQAw8yew",
        "outputId": "ac0eb0c8-42be-42ef-befc-4d43a72d963a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-938a309970c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmisses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'voc' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Ready-BoW-MLP, RF and Base.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}